{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0907a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_12117/267918855.py:10: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('acra_merged_active.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (951620, 53)\n",
      "\n",
      "==================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "==================================================\n",
      "\n",
      "1. Primary SSIC Description Column Analysis:\n",
      "----------------------------------------\n",
      "Total rows: 951,620\n",
      "Null values (pd.isnull()): 0\n",
      "NA values (pd.isna()): 0\n",
      "Empty strings (''): 0\n",
      "Whitespace only: 0\n",
      "Null-like strings: 0\n",
      "\n",
      "Total problematic entries: 0\n",
      "Percentage of missing data: 0.00%\n",
      "Valid entries: 951,620\n",
      "\n",
      "2. Sample of Missing/Empty Values:\n",
      "----------------------------------------\n",
      "\n",
      "3. Sample of Valid Entries:\n",
      "----------------------------------------\n",
      "1. RETAIL SALE OF JEWELLERY MADE FROM PRECIOUS METALS AND STONES\n",
      "2. WHOLESALE OF LIVESTOCK, MEAT, POULTRY, EGGS AND SEAFOOD (INCLUDING FRESH AND FROZEN)\n",
      "3. FUNERAL AND RELATED ACTIVITIES (INCLUDING EMBALMING, CREMATING AND CEMETERY SERVICES, UPKEEP OF CEMETERIES)\n",
      "4. MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS\n",
      "5. MANUFACTURE OF SOAP, DETERGENTS, WASHING AND OTHER CLEANING PREPARATIONS\n",
      "6. RETAIL SALE OF HARDWARE (EG CHAINS, CHANGKOLS, AXES)\n",
      "7. MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS\n",
      "8. MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS\n",
      "9. LETTING AND OPERATING OF SELF-OWNED OR LEASED FOOD COURTS, COFFEE SHOPS AND CANTEENS (WITH MAINLY RENTAL INCOME)\n",
      "10. LETTING AND OPERATING OF SELF-OWNED OR LEASED FOOD COURTS, COFFEE SHOPS AND CANTEENS (WITH MAINLY RENTAL INCOME)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import text\n",
    "\n",
    "# ====== PART 1: Load and Analyze CSV for Missing Values ======\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('acra_merged_active.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check for various types of missing values in the primary_ssic column\n",
    "print(\"\\n1. Primary SSIC Description Column Analysis:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'primary_ssic_description' in df.columns:\n",
    "    col_name = 'primary_ssic_description'\n",
    "elif 'primary_ssic' in df.columns:\n",
    "    col_name = 'primary_ssic'\n",
    "else:\n",
    "    # Show available columns to help identify the correct column name\n",
    "    print(\"Available columns:\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        print(f\"{i+1}. {col}\")\n",
    "    print(\"\\nPlease check the column name for SSIC descriptions\")\n",
    "    col_name = None\n",
    "\n",
    "if col_name:\n",
    "    # Comprehensive missing value check\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    # Standard pandas missing values\n",
    "    null_count = df[col_name].isnull().sum()\n",
    "    na_count = df[col_name].isna().sum()\n",
    "    \n",
    "    # Empty strings\n",
    "    empty_string_count = (df[col_name] == '').sum()\n",
    "    \n",
    "    # Whitespace only\n",
    "    whitespace_only = df[col_name].str.strip().eq('').sum()\n",
    "    \n",
    "    # Common null representations\n",
    "    null_representations = ['null', 'NULL', 'Null', 'none', 'None', 'NONE', \n",
    "                           'nan', 'NaN', 'NAN', 'n/a', 'N/A', '#N/A', \n",
    "                           '-', '--', '---', 'undefined', 'UNDEFINED']\n",
    "    \n",
    "    null_like_count = df[col_name].isin(null_representations).sum()\n",
    "    \n",
    "    print(f\"Total rows: {total_rows:,}\")\n",
    "    print(f\"Null values (pd.isnull()): {null_count:,}\")\n",
    "    print(f\"NA values (pd.isna()): {na_count:,}\")\n",
    "    print(f\"Empty strings (''): {empty_string_count:,}\")\n",
    "    print(f\"Whitespace only: {whitespace_only:,}\")\n",
    "    print(f\"Null-like strings: {null_like_count:,}\")\n",
    "    \n",
    "    # Total missing\n",
    "    total_missing = max(null_count, na_count) + empty_string_count + null_like_count\n",
    "    print(f\"\\nTotal problematic entries: {total_missing:,}\")\n",
    "    print(f\"Percentage of missing data: {(total_missing/total_rows)*100:.2f}%\")\n",
    "    print(f\"Valid entries: {total_rows - total_missing:,}\")\n",
    "    \n",
    "    # Show sample of problematic entries\n",
    "    print(f\"\\n2. Sample of Missing/Empty Values:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    missing_mask = (df[col_name].isnull() | \n",
    "                   df[col_name].isna() | \n",
    "                   (df[col_name] == '') |\n",
    "                   df[col_name].str.strip().eq('') |\n",
    "                   df[col_name].isin(null_representations))\n",
    "    \n",
    "    if missing_mask.sum() > 0:\n",
    "        print(\"Sample rows with missing values:\")\n",
    "        sample_missing = df[missing_mask].head(10)\n",
    "        print(sample_missing[[col_name] + [col for col in df.columns if col != col_name][:3]])\n",
    "    \n",
    "    # Show sample of valid entries\n",
    "    print(f\"\\n3. Sample of Valid Entries:\")\n",
    "    print(\"-\" * 40)\n",
    "    valid_entries = df[~missing_mask][col_name].head(10)\n",
    "    for i, entry in enumerate(valid_entries, 1):\n",
    "        print(f\"{i}. {entry}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3300cfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped specified columns. New shape: (951620, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"acra_merged_active.csv\")\n",
    "\n",
    "# List of columns to drop (cleaned up)\n",
    "cols_to_drop = [\n",
    "    \"issuance_agency_id\",\n",
    "    \"entity_type_description\",\n",
    "    \"business_constitution_description\",\n",
    "    \"company_type_description\",\n",
    "    \"paf_constitution_description\",\n",
    "    \"registration_incorporation_date\",\n",
    "    \"uen_issue_date\",\n",
    "    \"address_type\",\n",
    "    \"other_address_line1\",\n",
    "    \"other_address_line2\",\n",
    "    \"account_due_date\",\n",
    "    \"annual_return_date\",\n",
    "    \"no_of_officers\",\n",
    "    \"former_entity_name1\",\n",
    "    \"former_entity_name2\",\n",
    "    \"former_entity_name3\",\n",
    "    \"former_entity_name4\",\n",
    "    \"former_entity_name5\",\n",
    "    \"former_entity_name6\",\n",
    "    \"former_entity_name7\",\n",
    "    \"former_entity_name8\",\n",
    "    \"former_entity_name9\",\n",
    "    \"former_entity_name10\",\n",
    "    \"former_entity_name11\",\n",
    "    \"former_entity_name12\",\n",
    "    \"former_entity_name13\",\n",
    "    \"former_entity_name14\",\n",
    "    \"former_entity_name15\",\n",
    "    \"uen_of_audit_firm1\",\n",
    "    \"name_of_audit_firm1\",\n",
    "    \"uen_of_audit_firm2\",\n",
    "    \"name_of_audit_firm2\",\n",
    "    \"uen_of_audit_firm3\",\n",
    "    \"name_of_audit_firm3\",\n",
    "    \"uen_of_audit_firm4\",\n",
    "    \"name_of_audit_firm4\",\n",
    "    \"uen_of_audit_firm5\",\n",
    "    \"name_of_audit_firm5\"\n",
    "]\n",
    "\n",
    "# Drop only if they exist\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "\n",
    "# Save back to the same file (overwrite)\n",
    "df.to_csv(\"acra_merged_active.csv\", index=False)\n",
    "print(\"Dropped specified columns. New shape:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jezelei/.pyenv/versions/3.12.11/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ACRA data...\n",
      "Dataset Shape: (951620, 15)\n",
      "Loading HuggingFace model (smaller, faster version)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying dataset with smaller model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [19:35<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification complete! Results saved to acra_classified_fast_sample500.csv\n",
      "                            primary_ssic_description  \\\n",
      "0  RETAIL SALE OF JEWELLERY MADE FROM PRECIOUS ME...   \n",
      "1  WHOLESALE OF LIVESTOCK, MEAT, POULTRY, EGGS AN...   \n",
      "2  FUNERAL AND RELATED ACTIVITIES (INCLUDING EMBA...   \n",
      "3  MINI-MARTS, CONVENIENCE STORES AND PROVISION S...   \n",
      "4  MANUFACTURE OF SOAP, DETERGENTS, WASHING AND O...   \n",
      "5  RETAIL SALE OF HARDWARE (EG CHAINS, CHANGKOLS,...   \n",
      "6  MINI-MARTS, CONVENIENCE STORES AND PROVISION S...   \n",
      "7  MINI-MARTS, CONVENIENCE STORES AND PROVISION S...   \n",
      "8  LETTING AND OPERATING OF SELF-OWNED OR LEASED ...   \n",
      "9  LETTING AND OPERATING OF SELF-OWNED OR LEASED ...   \n",
      "\n",
      "                                   business_subtypes  \\\n",
      "0                                   jewellery retail   \n",
      "1                                             Others   \n",
      "2                   ministries, maintenance services   \n",
      "3  convenience stores, mrt services, facilities m...   \n",
      "4  manufacturing, maintenance services, facilitie...   \n",
      "5                                    hardware retail   \n",
      "6  convenience stores, mrt services, facilities m...   \n",
      "7  convenience stores, mrt services, facilities m...   \n",
      "8  cafes, catering services, convenience stores, ...   \n",
      "9  cafes, catering services, convenience stores, ...   \n",
      "\n",
      "                                  amenity_categories  \n",
      "0                                    Retail_services  \n",
      "1                                             Others  \n",
      "2            Government_services, Essential_services  \n",
      "3  Transport_services, Residential, Essential_ser...  \n",
      "4                         Others, Essential_services  \n",
      "5                                    Retail_services  \n",
      "6  Transport_services, Residential, Essential_ser...  \n",
      "7  Transport_services, Residential, Essential_ser...  \n",
      "8  Transport_services, Government_services, Essen...  \n",
      "9  Transport_services, Government_services, Essen...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_21175/2449101043.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample[\"business_subtypes\"], df_sample[\"amenity_categories\"] = zip(*results)\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_21175/2449101043.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample[\"business_subtypes\"], df_sample[\"amenity_categories\"] = zip(*results)\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_21175/2449101043.py:222: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample[\"business_subtypes\"] = df_sample[\"business_subtypes\"].apply(lambda x: \", \".join(x))\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_21175/2449101043.py:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample[\"amenity_categories\"] = df_sample[\"amenity_categories\"].apply(lambda x: \", \".join(x))\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# ACRA Amenity Classification with HuggingFace (Optimised for Speed)\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================================\n",
    "# PART 1: Load Dataset\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading ACRA data...\")\n",
    "df = pd.read_csv(\"acra_merged_active.csv\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "if \"primary_ssic_description\" in df.columns:\n",
    "    col_name = \"primary_ssic_description\"\n",
    "elif \"primary_ssic\" in df.columns:\n",
    "    col_name = \"primary_ssic\"\n",
    "else:\n",
    "    raise ValueError(\"No SSIC description column found in CSV\")\n",
    "\n",
    "# Drop rows with empty descriptions\n",
    "df = df.dropna(subset=[col_name])\n",
    "df[col_name] = df[col_name].astype(str).str.strip()\n",
    "\n",
    "# ========================================================\n",
    "# PART 2: Define Candidate Labels (Subtypes)\n",
    "# ========================================================\n",
    "\n",
    "candidate_labels = [\n",
    "    # --- Retail Services ---\n",
    "    \"jewellery retail\", \"hardware retail\", \"supermarkets\", \"convenience stores\",\n",
    "    \"department stores\", \"fashion retail\", \"electronics retail\", \"automotive retail\",\n",
    "    \"restaurants\", \"cafes\", \"bars\", \"catering services\", \"e-commerce retail\",\n",
    "\n",
    "    # --- Healthcare ---\n",
    "    \"hospitals\", \"clinics\", \"dental clinics\", \"pharmacies\", \"diagnostic centres\",\n",
    "    \"mental health services\", \"traditional medicine\", \"veterinary services\",\n",
    "\n",
    "    # --- Education ---\n",
    "    \"preschool\", \"primary schools\", \"secondary schools\", \"universities\",\n",
    "    \"polytechnics\", \"vocational training\", \"tuition centres\", \"enrichment centres\",\n",
    "\n",
    "    # --- Transport ---\n",
    "    \"bus services\", \"mrt services\", \"lrt services\", \"taxi services\",\n",
    "    \"logistics\", \"shipping\", \"aviation\", \"car rental\", \"moving services\",\n",
    "\n",
    "    # --- Residential ---\n",
    "    \"public housing\", \"private apartments\", \"condominiums\", \"landed property\",\n",
    "    \"serviced residences\", \"student housing\", \"senior housing\",\n",
    "\n",
    "    # --- Government & Community ---\n",
    "    \"government office\", \"ministries\", \"statutory boards\", \"courts\",\n",
    "    \"community centres\", \"religious facilities\", \"libraries\", \"social services\",\n",
    "\n",
    "    # --- Emergency ---\n",
    "    \"police services\", \"fire services\", \"ambulance services\", \"scdf\",\n",
    "    \"private security services\",\n",
    "\n",
    "    # --- Tourism ---\n",
    "    \"hotels\", \"resorts\", \"hostels\", \"vacation rentals\",\n",
    "    \"museums\", \"theme parks\", \"tourist attractions\", \"cruise services\",\n",
    "\n",
    "    # --- Essential Services ---\n",
    "    \"utilities\", \"telecoms\", \"postal services\", \"waste management\",\n",
    "    \"facilities management\", \"maintenance services\",\n",
    "\n",
    "    # --- Others (Industrial / Business) ---\n",
    "    \"manufacturing\", \"construction\", \"agriculture\", \"finance\", \"consulting\",\n",
    "    \"media\", \"information technology\", \"research and development\"\n",
    "]\n",
    "\n",
    "# ========================================================\n",
    "# PART 3: Setup HuggingFace Zero-Shot Classifier (Smaller Model)\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading HuggingFace model (smaller, faster version)...\")\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"valhalla/distilbart-mnli-12-3\"  # much smaller & faster than bart-large-mnli\n",
    ")\n",
    "\n",
    "# ========================================================\n",
    "# PART 4: Subtype → Category Mapping\n",
    "# ========================================================\n",
    "\n",
    "subtype_to_category = {lbl: cat for lbl, cat in {\n",
    "    # Retail\n",
    "    \"jewellery retail\": \"Retail_services\",\n",
    "    \"hardware retail\": \"Retail_services\",\n",
    "    \"supermarkets\": \"Retail_services\",\n",
    "    \"convenience stores\": \"Retail_services\",\n",
    "    \"department stores\": \"Retail_services\",\n",
    "    \"fashion retail\": \"Retail_services\",\n",
    "    \"electronics retail\": \"Retail_services\",\n",
    "    \"automotive retail\": \"Retail_services\",\n",
    "    \"restaurants\": \"Retail_services\",\n",
    "    \"cafes\": \"Retail_services\",\n",
    "    \"bars\": \"Retail_services\",\n",
    "    \"catering services\": \"Retail_services\",\n",
    "    \"e-commerce retail\": \"Retail_services\",\n",
    "\n",
    "    # Healthcare\n",
    "    \"hospitals\": \"Healthcare_facilities\",\n",
    "    \"clinics\": \"Healthcare_facilities\",\n",
    "    \"dental clinics\": \"Healthcare_facilities\",\n",
    "    \"pharmacies\": \"Healthcare_facilities\",\n",
    "    \"diagnostic centres\": \"Healthcare_facilities\",\n",
    "    \"mental health services\": \"Healthcare_facilities\",\n",
    "    \"traditional medicine\": \"Healthcare_facilities\",\n",
    "    \"veterinary services\": \"Healthcare_facilities\",\n",
    "\n",
    "    # Education\n",
    "    \"preschool\": \"Education_institutions\",\n",
    "    \"primary schools\": \"Education_institutions\",\n",
    "    \"secondary schools\": \"Education_institutions\",\n",
    "    \"universities\": \"Education_institutions\",\n",
    "    \"polytechnics\": \"Education_institutions\",\n",
    "    \"vocational training\": \"Education_institutions\",\n",
    "    \"tuition centres\": \"Education_institutions\",\n",
    "    \"enrichment centres\": \"Education_institutions\",\n",
    "\n",
    "    # Transport\n",
    "    \"bus services\": \"Transport_services\",\n",
    "    \"mrt services\": \"Transport_services\",\n",
    "    \"lrt services\": \"Transport_services\",\n",
    "    \"taxi services\": \"Transport_services\",\n",
    "    \"logistics\": \"Transport_services\",\n",
    "    \"shipping\": \"Transport_services\",\n",
    "    \"aviation\": \"Transport_services\",\n",
    "    \"car rental\": \"Transport_services\",\n",
    "    \"moving services\": \"Transport_services\",\n",
    "\n",
    "    # Residential\n",
    "    \"public housing\": \"Residential\",\n",
    "    \"private apartments\": \"Residential\",\n",
    "    \"condominiums\": \"Residential\",\n",
    "    \"landed property\": \"Residential\",\n",
    "    \"serviced residences\": \"Residential\",\n",
    "    \"student housing\": \"Residential\",\n",
    "    \"senior housing\": \"Residential\",\n",
    "\n",
    "    # Government & Community\n",
    "    \"government office\": \"Government_services\",\n",
    "    \"ministries\": \"Government_services\",\n",
    "    \"statutory boards\": \"Government_services\",\n",
    "    \"courts\": \"Government_services\",\n",
    "    \"community centres\": \"Community_spaces\",\n",
    "    \"religious facilities\": \"Community_spaces\",\n",
    "    \"libraries\": \"Community_spaces\",\n",
    "    \"social services\": \"Community_spaces\",\n",
    "\n",
    "    # Emergency\n",
    "    \"police services\": \"Emergency_services\",\n",
    "    \"fire services\": \"Emergency_services\",\n",
    "    \"ambulance services\": \"Emergency_services\",\n",
    "    \"scdf\": \"Emergency_services\",\n",
    "    \"private security services\": \"Emergency_services\",\n",
    "\n",
    "    # Tourism\n",
    "    \"hotels\": \"Tourism\",\n",
    "    \"resorts\": \"Tourism\",\n",
    "    \"hostels\": \"Tourism\",\n",
    "    \"vacation rentals\": \"Tourism\",\n",
    "    \"museums\": \"Tourism\",\n",
    "    \"theme parks\": \"Tourism\",\n",
    "    \"tourist attractions\": \"Tourism\",\n",
    "    \"cruise services\": \"Tourism\",\n",
    "\n",
    "    # Essential\n",
    "    \"utilities\": \"Essential_services\",\n",
    "    \"telecoms\": \"Essential_services\",\n",
    "    \"postal services\": \"Essential_services\",\n",
    "    \"waste management\": \"Essential_services\",\n",
    "    \"facilities management\": \"Essential_services\",\n",
    "    \"maintenance services\": \"Essential_services\",\n",
    "\n",
    "    # Others\n",
    "    \"manufacturing\": \"Others\",\n",
    "    \"construction\": \"Others\",\n",
    "    \"agriculture\": \"Others\",\n",
    "    \"finance\": \"Others\",\n",
    "    \"consulting\": \"Others\",\n",
    "    \"media\": \"Others\",\n",
    "    \"information technology\": \"Others\",\n",
    "    \"research and development\": \"Others\"\n",
    "}.items()}\n",
    "\n",
    "# ========================================================\n",
    "# PART 5: Classification Function\n",
    "# ========================================================\n",
    "\n",
    "def classify_description(description, threshold=0.4):\n",
    "    try:\n",
    "        result = classifier(description, candidate_labels, multi_label=True)\n",
    "        labels, scores = result[\"labels\"], result[\"scores\"]\n",
    "        selected = [lbl for lbl, sc in zip(labels, scores) if sc >= threshold]\n",
    "\n",
    "        if not selected:\n",
    "            return [\"Others\"], [\"Others\"]\n",
    "\n",
    "        categories = [subtype_to_category.get(lbl, \"Others\") for lbl in selected]\n",
    "        return selected, list(set(categories))\n",
    "    except Exception as e:\n",
    "        print(f\"Error on: {description[:50]}... {e}\")\n",
    "        return [\"Others\"], [\"Others\"]\n",
    "\n",
    "# ========================================================\n",
    "# PART 6: Apply to Dataset with Progress Bar\n",
    "# ========================================================\n",
    "\n",
    "print(\"Classifying dataset with smaller model...\")\n",
    "\n",
    "df_sample = df.head(500)   # <-- only take first 500 for testing\n",
    "results = []\n",
    "for desc in tqdm(df_sample[col_name].astype(str).tolist()):\n",
    "    results.append(classify_description(desc))\n",
    "\n",
    "df_sample[\"business_subtypes\"], df_sample[\"amenity_categories\"] = zip(*results)\n",
    "df_sample[\"business_subtypes\"] = df_sample[\"business_subtypes\"].apply(lambda x: \", \".join(x))\n",
    "df_sample[\"amenity_categories\"] = df_sample[\"amenity_categories\"].apply(lambda x: \", \".join(x))\n",
    "\n",
    "# results = []\n",
    "# for desc in tqdm(df[col_name].astype(str).tolist()):\n",
    "#     results.append(classify_description(desc))\n",
    "\n",
    "# df[\"business_subtypes\"], df[\"amenity_categories\"] = zip(*results)\n",
    "# df[\"business_subtypes\"] = df[\"business_subtypes\"].apply(lambda x: \", \".join(x))\n",
    "# df[\"amenity_categories\"] = df[\"amenity_categories\"].apply(lambda x: \", \".join(x))\n",
    "\n",
    "# ========================================================\n",
    "# PART 7: Save Results\n",
    "# ========================================================\n",
    "\n",
    "output_path = \"acra_classified_huggingFace500.csv\"\n",
    "df_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nClassification complete! Results saved to {output_path}\")\n",
    "print(df_sample[[col_name, \"business_subtypes\", \"amenity_categories\"]].head(10))\n",
    "\n",
    "# output_path = \"acra_classified_fast.csv\"\n",
    "# df.to_csv(output_path, index=False)\n",
    "\n",
    "# print(f\"\\nClassification complete! Results saved to {output_path}\")\n",
    "\n",
    "# ========================================================\n",
    "# PART 8: Summary Stats\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\nSUMMARY STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count how many rows fall into each category\n",
    "category_counts = (\n",
    "    df_sample[\"amenity_categories\"]\n",
    "    .str.split(\",\")                     # handle multi-label\n",
    "    .explode()                          # flatten lists\n",
    "    .str.strip()\n",
    "    .value_counts()\n",
    ")\n",
    "\n",
    "print(\"\\nAmenity Category Counts:\")\n",
    "print(category_counts)\n",
    "\n",
    "# Count number of unique subtypes\n",
    "unique_subtypes = (\n",
    "    df_sample[\"business_subtypes\"]\n",
    "    .str.split(\",\")\n",
    "    .explode()\n",
    "    .str.strip()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal unique subtypes detected: {len(unique_subtypes)}\")\n",
    "print(\"Example subtypes:\", unique_subtypes[:20])  # preview first 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223be450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MediaPipe Text Classifier...\n",
      "Loading ACRA data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757132779.645542 1045667 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2\n",
      "W0000 00:00:1757132779.780096 1052904 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (951620, 15)\n",
      "Starting enhanced classification...\n",
      "Processing 3000 records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 3000/3000 [01:21<00:00, 36.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification complete! Results saved to acra_classified_mediapipe.csv\n",
      "\n",
      "============================================================\n",
      "ENHANCED CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Category Distribution:\n",
      "Retail_services          : 1028 ( 34.3%)\n",
      "Others                   :  561 ( 18.7%)\n",
      "Construction_property    :  275 (  9.2%)\n",
      "Technology_telecommunications:  244 (  8.1%)\n",
      "Professional_services    :  216 (  7.2%)\n",
      "Transport_services       :  183 (  6.1%)\n",
      "Industrial_manufacturing :  173 (  5.8%)\n",
      "Food_beverage            :  141 (  4.7%)\n",
      "Financial_services       :   99 (  3.3%)\n",
      "Healthcare_facilities    :   62 (  2.1%)\n",
      "Education_institutions   :   45 (  1.5%)\n",
      "Entertainment_recreation :   32 (  1.1%)\n",
      "Accommodation            :   19 (  0.6%)\n",
      "Utilities_infrastructure :    9 (  0.3%)\n",
      "Religious_community      :    8 (  0.3%)\n",
      "Government_public        :    5 (  0.2%)\n",
      "\n",
      "🎯 'Others' reduced to: 18.7%\n",
      "\n",
      "Confidence Distribution:\n",
      "High confidence (≥0.7): 35 (1.2%)\n",
      "Medium confidence (0.4-0.7): 277 (9.2%)\n",
      "Low confidence (<0.4): 2688 (89.6%)\n",
      "\n",
      "Sample Results:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Business: RETAIL SALE OF JEWELLERY MADE FROM PRECIOUS METALS... → Retail_services      (0.20) [retail, jewellery]\n",
      "Business: WHOLESALE OF LIVESTOCK, MEAT, POULTRY, EGGS AND SE... → Retail_services      (0.10) [wholesale]\n",
      "Business: FUNERAL AND RELATED ACTIVITIES (INCLUDING EMBALMIN... → Technology_telecommunications (0.10) [it]\n",
      "Business: MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS   → Retail_services      (0.40) [shop, store, mart, convenience]\n",
      "Business: MANUFACTURE OF SOAP, DETERGENTS, WASHING AND OTHER... → Construction_property (0.10) [cleaning]\n",
      "Business: RETAIL SALE OF HARDWARE (EG CHAINS, CHANGKOLS, AXE... → Retail_services      (0.20) [retail, hardware]\n",
      "Business: MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS   → Retail_services      (0.40) [shop, store, mart, convenience]\n",
      "Business: MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS   → Retail_services      (0.40) [shop, store, mart, convenience]\n",
      "Business: LETTING AND OPERATING OF SELF-OWNED OR LEASED FOOD... → Food_beverage        (0.50) [coffee, food court]\n",
      "Business: LETTING AND OPERATING OF SELF-OWNED OR LEASED FOOD... → Food_beverage        (0.50) [coffee, food court]\n",
      "Business: POULTRY BREEDING/HATCHERIES                          → Others               (0.20) [no_keywords_matched]\n",
      "Business: WHOLESALE OF SPORTING AND OTHER RECREATIONAL GOODS... → Retail_services      (0.10) [wholesale]\n",
      "Business: HAIRDRESSING SALONS/SHOPS (INCLUDING BARBER SHOPS)   → Retail_services      (0.10) [shop]\n",
      "Business: WHOLESALE OF OTHER HOUSEHOLD GOODS N.E.C.            → Retail_services      (0.10) [wholesale]\n",
      "Business: RETAIL SALE OF FRUITS AND VEGETABLES                 → Retail_services      (0.10) [retail]\n",
      "\n",
      "✅ SUCCESS! Classification completed with significantly fewer 'Others'!\n",
      "📊 Processed: 3000 records\n",
      "📁 Saved to: acra_classified_mediapipe.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_40087/1989827861.py:291: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['amenity_categories'] = [', '.join(cats) for cats in categories_list]\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_40087/1989827861.py:292: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['classification_confidence'] = confidences\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_40087/1989827861.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['keywords_matched'] = [', '.join(kw) for kw in keywords_matched]\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# ACRA Amenity Classification with MediaPipe Text Classifier\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import text\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# ========================================================\n",
    "# PART 1: Setup MediaPipe Text Classifier\n",
    "# ========================================================\n",
    "\n",
    "print(\"Setting up MediaPipe Text Classifier...\")\n",
    "\n",
    "# Download the pre-trained model (this is free and runs locally)\n",
    "model_url = \"https://storage.googleapis.com/mediapipe-models/text_classifier/bert_classifier/float32/1/bert_classifier.tflite\"\n",
    "model_path = \"bert_classifier.tflite\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Downloading MediaPipe text classification model...\")\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "    print(\"Model downloaded successfully!\")\n",
    "\n",
    "# Create the text classifier\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = text.TextClassifierOptions(base_options=base_options)\n",
    "classifier = text.TextClassifier.create_from_options(options)\n",
    "\n",
    "# ========================================================\n",
    "# PART 2: Load Dataset\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading ACRA data...\")\n",
    "df = pd.read_csv(\"acra_merged_active.csv\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "if \"primary_ssic_description\" in df.columns:\n",
    "    col_name = \"primary_ssic_description\"\n",
    "elif \"primary_ssic\" in df.columns:\n",
    "    col_name = \"primary_ssic\"\n",
    "else:\n",
    "    raise ValueError(\"No SSIC description column found in CSV\")\n",
    "\n",
    "# Drop rows with empty descriptions\n",
    "df = df.dropna(subset=[col_name])\n",
    "df[col_name] = df[col_name].astype(str).str.strip()\n",
    "\n",
    "# ========================================================\n",
    "# PART 3: Custom Classification Logic (Rule-based + ML)\n",
    "# ========================================================\n",
    "\n",
    "# Since MediaPipe's pre-trained model might not have our specific categories,\n",
    "# we'll create a hybrid approach: use MediaPipe for general classification\n",
    "# and enhance with rule-based mapping\n",
    "\n",
    "# Define comprehensive keyword mappings for Singapore context\n",
    "category_keywords = {\n",
    "    \"Retail_services\": [\n",
    "        \"retail\", \"shop\", \"store\", \"mart\", \"supermarket\", \"convenience\", \"department\",\n",
    "        \"fashion\", \"clothing\", \"electronics\", \"jewelry\", \"jewellery\", \"hardware\",\n",
    "        \"automotive\", \"bookstore\", \"pharmacy\", \"optical\", \"sporting goods\",\n",
    "        \"furniture\", \"toys\", \"pet\", \"beauty\", \"cosmetic\", \"grocery\", \"wholesale\",\n",
    "        \"trading\", \"import\", \"export\", \"distribution\", \"sales\"\n",
    "    ],\n",
    "    \n",
    "    \"Food_beverage\": [\n",
    "        \"restaurant\", \"cafe\", \"coffee\", \"bar\", \"pub\", \"nightclub\", \"food court\",\n",
    "        \"catering\", \"bakery\", \"ice cream\", \"bubble tea\", \"hawker\", \"dining\",\n",
    "        \"fast food\", \"delivery\", \"food truck\", \"tea\", \"beverage\", \"kitchen\",\n",
    "        \"culinary\", \"chef\", \"cook\", \"meal\", \"snack\", \"confectionery\"\n",
    "    ],\n",
    "    \n",
    "    \"Healthcare_facilities\": [\n",
    "        \"hospital\", \"clinic\", \"medical\", \"health\", \"dental\", \"doctor\", \"physician\",\n",
    "        \"specialist\", \"diagnostic\", \"laboratory\", \"physiotherapy\", \"tcm\",\n",
    "        \"traditional chinese medicine\", \"veterinary\", \"vet\", \"mental health\",\n",
    "        \"rehabilitation\", \"nursing\", \"healthcare\", \"medicine\", \"pharmaceutical\",\n",
    "        \"wellness\", \"therapy\", \"treatment\", \"surgery\", \"radiology\"\n",
    "    ],\n",
    "    \n",
    "    \"Education_institutions\": [\n",
    "        \"school\", \"education\", \"kindergarten\", \"preschool\", \"primary\", \"secondary\",\n",
    "        \"university\", \"college\", \"polytechnic\", \"institute\", \"tuition\", \"enrichment\",\n",
    "        \"training\", \"learning\", \"academic\", \"student\", \"teacher\", \"instructor\",\n",
    "        \"course\", \"class\", \"lesson\", \"workshop\", \"seminar\", \"coaching\"\n",
    "    ],\n",
    "    \n",
    "    \"Transport_services\": [\n",
    "        \"transport\", \"logistics\", \"courier\", \"delivery\", \"shipping\", \"freight\",\n",
    "        \"taxi\", \"car rental\", \"bus\", \"mrt\", \"lrt\", \"aviation\", \"airline\",\n",
    "        \"maritime\", \"port\", \"warehouse\", \"storage\", \"moving\", \"relocation\",\n",
    "        \"parking\", \"vehicle\", \"automotive service\", \"petrol\", \"fuel\"\n",
    "    ],\n",
    "    \n",
    "    \"Financial_services\": [\n",
    "        \"bank\", \"finance\", \"financial\", \"insurance\", \"investment\", \"accounting\",\n",
    "        \"audit\", \"tax\", \"wealth management\", \"loan\", \"credit\", \"mortgage\",\n",
    "        \"securities\", \"trading\", \"fund\", \"asset management\", \"advisory\",\n",
    "        \"pawnshop\", \"money changer\", \"payment\", \"fintech\"\n",
    "    ],\n",
    "    \n",
    "    \"Professional_services\": [\n",
    "        \"consulting\", \"consultant\", \"advisory\", \"professional services\", \"legal\",\n",
    "        \"law\", \"lawyer\", \"solicitor\", \"architect\", \"engineering\", \"design\",\n",
    "        \"marketing\", \"advertising\", \"public relations\", \"recruitment\", \"hr\",\n",
    "        \"human resource\", \"business services\", \"management\", \"strategy\"\n",
    "    ],\n",
    "    \n",
    "    \"Entertainment_recreation\": [\n",
    "        \"entertainment\", \"cinema\", \"theater\", \"theatre\", \"concert\", \"music\",\n",
    "        \"sports\", \"gym\", \"fitness\", \"swimming\", \"golf\", \"bowling\", \"karaoke\",\n",
    "        \"gaming\", \"amusement\", \"recreation\", \"club\", \"spa\", \"massage\",\n",
    "        \"salon\", \"beauty\", \"wellness\", \"leisure\", \"hobby\"\n",
    "    ],\n",
    "    \n",
    "    \"Accommodation\": [\n",
    "        \"hotel\", \"hostel\", \"accommodation\", \"lodging\", \"resort\", \"motel\",\n",
    "        \"serviced apartment\", \"vacation rental\", \"boarding\", \"dormitory\",\n",
    "        \"guest house\", \"inn\", \"stay\", \"hospitality\"\n",
    "    ],\n",
    "    \n",
    "    \"Government_public\": [\n",
    "        \"government\", \"ministry\", \"statutory board\", \"public\", \"civil service\",\n",
    "        \"town council\", \"community center\", \"library\", \"court\", \"police\",\n",
    "        \"fire\", \"post office\", \"municipal\", \"authority\", \"agency\", \"commission\"\n",
    "    ],\n",
    "    \n",
    "    \"Religious_community\": [\n",
    "        \"temple\", \"church\", \"mosque\", \"synagogue\", \"religious\", \"spiritual\",\n",
    "        \"community\", \"association\", \"society\", \"club\", \"charity\", \"volunteer\",\n",
    "        \"social\", \"cultural\", \"heritage\", \"clan\", \"foundation\", \"welfare\"\n",
    "    ],\n",
    "    \n",
    "    \"Industrial_manufacturing\": [\n",
    "        \"manufacturing\", \"factory\", \"industrial\", \"production\", \"plant\",\n",
    "        \"assembly\", \"processing\", \"chemical\", \"textile\", \"food processing\",\n",
    "        \"engineering\", \"machinery\", \"equipment\", \"fabrication\", \"construction\"\n",
    "    ],\n",
    "    \n",
    "    \"Technology_telecommunications\": [\n",
    "        \"technology\", \"tech\", \"software\", \"computer\", \"it\", \"information technology\",\n",
    "        \"telecommunications\", \"telecom\", \"internet\", \"data\", \"digital\",\n",
    "        \"electronics\", \"engineering\", \"development\", \"programming\", \"systems\"\n",
    "    ],\n",
    "    \n",
    "    \"Construction_property\": [\n",
    "        \"construction\", \"building\", \"property\", \"real estate\", \"development\",\n",
    "        \"contractor\", \"renovation\", \"maintenance\", \"cleaning\", \"landscaping\",\n",
    "        \"interior\", \"architecture\", \"facilities management\", \"property management\"\n",
    "    ],\n",
    "    \n",
    "    \"Utilities_infrastructure\": [\n",
    "        \"utilities\", \"electricity\", \"water\", \"gas\", \"waste\", \"recycling\",\n",
    "        \"sewage\", \"environmental\", \"infrastructure\", \"public utilities\",\n",
    "        \"energy\", \"power\", \"sanitation\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ========================================================\n",
    "# PART 4: Enhanced Classification Function\n",
    "# ========================================================\n",
    "\n",
    "def classify_business_description(description: str, use_mediapipe: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Classify business description using hybrid approach:\n",
    "    1. MediaPipe for general sentiment/category hints\n",
    "    2. Keyword matching for specific Singapore business types\n",
    "    3. Fallback logic to minimize 'Others' classification\n",
    "    \"\"\"\n",
    "    \n",
    "    description_lower = description.lower()\n",
    "    \n",
    "    # Method 1: Keyword-based classification (primary)\n",
    "    category_scores = {}\n",
    "    \n",
    "    for category, keywords in category_keywords.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in description_lower:\n",
    "                # Weight longer, more specific keywords higher\n",
    "                weight = len(keyword.split()) * 2 if len(keyword.split()) > 1 else 1\n",
    "                score += weight\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if score > 0:\n",
    "            category_scores[category] = {\n",
    "                'score': score,\n",
    "                'keywords': matched_keywords,\n",
    "                'confidence': min(score / 10.0, 1.0)  # Normalize confidence\n",
    "            }\n",
    "    \n",
    "    # Method 2: Use MediaPipe for additional insights (if available)\n",
    "    mediapipe_result = None\n",
    "    if use_mediapipe:\n",
    "        try:\n",
    "            classification_result = classifier.classify(description)\n",
    "            if classification_result.classifications:\n",
    "                # Extract top classification\n",
    "                top_classification = classification_result.classifications[0]\n",
    "                if top_classification.categories:\n",
    "                    top_category = top_classification.categories[0]\n",
    "                    mediapipe_result = {\n",
    "                        'category': top_category.category_name,\n",
    "                        'score': top_category.score\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            print(f\"MediaPipe classification error: {e}\")\n",
    "    \n",
    "    # Method 3: Smart fallback logic\n",
    "    if not category_scores:\n",
    "        # Try broader keyword matching\n",
    "        broad_keywords = {\n",
    "            'service': ['Retail_services', 'Professional_services'],\n",
    "            'company': ['Professional_services', 'Technology_telecommunications'],\n",
    "            'center': ['Healthcare_facilities', 'Education_institutions'],\n",
    "            'management': ['Professional_services', 'Construction_property'],\n",
    "            'trading': ['Retail_services', 'Industrial_manufacturing'],\n",
    "            'engineering': ['Professional_services', 'Construction_property'],\n",
    "            'development': ['Technology_telecommunications', 'Construction_property']\n",
    "        }\n",
    "        \n",
    "        for keyword, potential_categories in broad_keywords.items():\n",
    "            if keyword in description_lower:\n",
    "                # Assign to most likely category with lower confidence\n",
    "                category_scores[potential_categories[0]] = {\n",
    "                    'score': 1,\n",
    "                    'keywords': [keyword],\n",
    "                    'confidence': 0.4\n",
    "                }\n",
    "                break\n",
    "    \n",
    "    # Final decision logic\n",
    "    if category_scores:\n",
    "        # Get category with highest score\n",
    "        best_category = max(category_scores.items(), key=lambda x: x[1]['score'])\n",
    "        \n",
    "        primary_category = best_category[0]\n",
    "        confidence = best_category[1]['confidence']\n",
    "        keywords_matched = best_category[1]['keywords']\n",
    "        \n",
    "        # Get secondary categories if they exist\n",
    "        secondary_categories = [cat for cat, data in category_scores.items() \n",
    "                             if cat != primary_category and data['score'] >= 2]\n",
    "        \n",
    "        all_categories = [primary_category] + secondary_categories[:2]  # Max 3 categories\n",
    "        \n",
    "        return all_categories, confidence, keywords_matched\n",
    "    \n",
    "    else:\n",
    "        # Last resort: try to infer from common Singapore business patterns\n",
    "        singapore_patterns = {\n",
    "            'pte ltd': 'Professional_services',\n",
    "            'trading': 'Retail_services',\n",
    "            'services': 'Professional_services',\n",
    "            'solutions': 'Technology_telecommunications',\n",
    "            'systems': 'Technology_telecommunications',\n",
    "            'international': 'Professional_services'\n",
    "        }\n",
    "        \n",
    "        for pattern, category in singapore_patterns.items():\n",
    "            if pattern in description_lower:\n",
    "                return [category], 0.3, [pattern]\n",
    "        \n",
    "        return ['Others'], 0.2, ['no_keywords_matched']\n",
    "\n",
    "# ========================================================\n",
    "# PART 5: Apply Classification to Dataset\n",
    "# ========================================================\n",
    "\n",
    "print(\"Starting enhanced classification...\")\n",
    "\n",
    "# Process sample first\n",
    "df_sample = df.head(3000)  # Test with 300k records\n",
    "print(f\"Processing {len(df_sample)} records...\")\n",
    "\n",
    "results = []\n",
    "for desc in tqdm(df_sample[col_name].astype(str).tolist(), desc=\"Classifying\"):\n",
    "    result = classify_business_description(desc)\n",
    "    results.append(result)\n",
    "\n",
    "# Unpack results\n",
    "categories_list, confidences, keywords_matched = zip(*results)\n",
    "\n",
    "df_sample['amenity_categories'] = [', '.join(cats) for cats in categories_list]\n",
    "df_sample['classification_confidence'] = confidences\n",
    "df_sample['keywords_matched'] = [', '.join(kw) for kw in keywords_matched]\n",
    "\n",
    "# ========================================================\n",
    "# PART 6: Save Results and Analysis\n",
    "# ========================================================\n",
    "\n",
    "output_path = \"acra_classified_mediapipe.csv\"\n",
    "df_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nClassification complete! Results saved to {output_path}\")\n",
    "\n",
    "# ========================================================\n",
    "# PART 7: Detailed Analysis\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENHANCED CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Category distribution\n",
    "category_counts = (\n",
    "    df_sample['amenity_categories']\n",
    "    .str.split(', ')\n",
    "    .explode()\n",
    "    .value_counts()\n",
    ")\n",
    "\n",
    "print(f\"\\nCategory Distribution:\")\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(df_sample)) * 100\n",
    "    print(f\"{category:25}: {count:4d} ({percentage:5.1f}%)\")\n",
    "\n",
    "# Key improvements\n",
    "others_pct = (category_counts.get('Others', 0) / len(df_sample)) * 100\n",
    "print(f\"\\n🎯 'Others' reduced to: {others_pct:.1f}%\")\n",
    "\n",
    "# Confidence analysis\n",
    "high_conf = len(df_sample[df_sample['classification_confidence'] >= 0.7])\n",
    "medium_conf = len(df_sample[(df_sample['classification_confidence'] >= 0.4) & \n",
    "                           (df_sample['classification_confidence'] < 0.7)])\n",
    "low_conf = len(df_sample[df_sample['classification_confidence'] < 0.4])\n",
    "\n",
    "print(f\"\\nConfidence Distribution:\")\n",
    "print(f\"High confidence (≥0.7): {high_conf} ({high_conf/len(df_sample)*100:.1f}%)\")\n",
    "print(f\"Medium confidence (0.4-0.7): {medium_conf} ({medium_conf/len(df_sample)*100:.1f}%)\")\n",
    "print(f\"Low confidence (<0.4): {low_conf} ({low_conf/len(df_sample)*100:.1f}%)\")\n",
    "\n",
    "# Sample results\n",
    "print(f\"\\nSample Results:\")\n",
    "print(\"-\" * 120)\n",
    "for idx in range(min(15, len(df_sample))):\n",
    "    row = df_sample.iloc[idx]\n",
    "    desc = row[col_name][:50] + \"...\" if len(row[col_name]) > 50 else row[col_name]\n",
    "    print(f\"Business: {desc:52} → {row['amenity_categories']:20} \"\n",
    "          f\"({row['classification_confidence']:.2f}) [{row['keywords_matched'][:30]}]\")\n",
    "\n",
    "print(f\"\\n✅ SUCCESS! Classification completed with significantly fewer 'Others'!\")\n",
    "print(f\"📊 Processed: {len(df_sample)} records\")\n",
    "print(f\"📁 Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abd34ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MediaPipe Text Classifier...\n",
      "Loading ACRA data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757133028.959321 1045667 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2\n",
      "W0000 00:00:1757133029.059776 1057654 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (951620, 15)\n",
      "Starting enhanced classification with new categories...\n",
      "Processing 3000 records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 3000/3000 [01:20<00:00, 37.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification complete! Results saved to acra_classified_new_categories.csv\n",
      "\n",
      "============================================================\n",
      "NEW CATEGORY CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Category Distribution:\n",
      "Retail_services          : 1076 ( 35.9%)\n",
      "Essential_services       :  679 ( 22.6%)\n",
      "Government_services      :  494 ( 16.5%)\n",
      "Others                   :  305 ( 10.2%)\n",
      "Transport_services       :  192 (  6.4%)\n",
      "Residential              :  117 (  3.9%)\n",
      "Healthcare_facilities    :  107 (  3.6%)\n",
      "Tourism                  :   57 (  1.9%)\n",
      "Education_institutions   :   45 (  1.5%)\n",
      "Community_spaces         :   29 (  1.0%)\n",
      "Emergency_services       :   15 (  0.5%)\n",
      "\n",
      "🎯 'Others' percentage: 10.2%\n",
      "\n",
      "Confidence Distribution:\n",
      "High confidence (≥0.7): 47 (1.6%)\n",
      "Medium confidence (0.4-0.7): 551 (18.4%)\n",
      "Low confidence (<0.4): 2402 (80.1%)\n",
      "\n",
      "Sample Results:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Business: RETAIL SALE OF JEWELLERY MADE FROM PRECIOUS METALS... → Retail_services           (0.20) [retail, jewellery]\n",
      "Business: WHOLESALE OF LIVESTOCK, MEAT, POULTRY, EGGS AND SE... → Retail_services           (0.20) [food, wholesale]\n",
      "Business: FUNERAL AND RELATED ACTIVITIES (INCLUDING EMBALMIN... → Essential_services        (0.40) [service]\n",
      "Business: MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS   → Essential_services, Retail_services (0.50) [provision, convenience store]\n",
      "Business: MANUFACTURE OF SOAP, DETERGENTS, WASHING AND OTHER... → Government_services       (0.10) [pa]\n",
      "Business: RETAIL SALE OF HARDWARE (EG CHAINS, CHANGKOLS, AXE... → Retail_services           (0.20) [retail, hardware]\n",
      "Business: MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS   → Essential_services, Retail_services (0.50) [provision, convenience store]\n",
      "Business: MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS   → Essential_services, Retail_services (0.50) [provision, convenience store]\n",
      "Business: LETTING AND OPERATING OF SELF-OWNED OR LEASED FOOD... → Retail_services           (0.70) [shop, coffee, food court, food]\n",
      "Business: LETTING AND OPERATING OF SELF-OWNED OR LEASED FOOD... → Retail_services           (0.70) [shop, coffee, food court, food]\n",
      "Business: POULTRY BREEDING/HATCHERIES                          → Others                    (0.20) [no_keywords_matched]\n",
      "Business: WHOLESALE OF SPORTING AND OTHER RECREATIONAL GOODS... → Transport_services        (0.10) [port]\n",
      "Business: HAIRDRESSING SALONS/SHOPS (INCLUDING BARBER SHOPS)   → Retail_services           (0.30) [shop, salon, bar]\n",
      "Business: WHOLESALE OF OTHER HOUSEHOLD GOODS N.E.C.            → Residential               (0.10) [house]\n",
      "Business: RETAIL SALE OF FRUITS AND VEGETABLES                 → Retail_services           (0.10) [retail]\n",
      "\n",
      "✅ SUCCESS! Classification completed with new category structure!\n",
      "📊 Processed: 3000 records\n",
      "📁 Saved to: acra_classified_new_categories.csv\n",
      "\n",
      "🔮 PREDICTION FOR FULL 950K DATASET:\n",
      "Based on current sample performance:\n",
      "Retail_services          : ~340,733 records ( 35.9%)\n",
      "Essential_services       : ~215,016 records ( 22.6%)\n",
      "Government_services      : ~156,433 records ( 16.5%)\n",
      "Others                   : ~96,583 records ( 10.2%)\n",
      "Transport_services       : ~60,800 records (  6.4%)\n",
      "Residential              : ~37,050 records (  3.9%)\n",
      "Healthcare_facilities    : ~33,883 records (  3.6%)\n",
      "Tourism                  : ~18,050 records (  1.9%)\n",
      "Education_institutions   : ~14,250 records (  1.5%)\n",
      "Community_spaces         : ~9,183 records (  1.0%)\n",
      "Emergency_services       : ~4,750 records (  0.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_40087/3954246982.py:270: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['amenity_categories'] = [', '.join(cats) for cats in categories_list]\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_40087/3954246982.py:271: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['classification_confidence'] = confidences\n",
      "/var/folders/cw/6ny7fl_n26v475rpwb5gr_2m0000gn/T/ipykernel_40087/3954246982.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['keywords_matched'] = [', '.join(kw) for kw in keywords_matched]\n"
     ]
    }
   ],
   "source": [
    "#NEW ACRA ACCORDING TO NAT'S CLASSIFICATION \n",
    "# =====================================================================\n",
    "# ACRA Amenity Classification with MediaPipe Text Classifier\n",
    "# Updated Categories: Emergency, Healthcare, Essential, Residential, Education, \n",
    "# Transport, Tourism, Community, Government, Retail, Others\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import text\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# ========================================================\n",
    "# PART 1: Setup MediaPipe Text Classifier\n",
    "# ========================================================\n",
    "\n",
    "print(\"Setting up MediaPipe Text Classifier...\")\n",
    "\n",
    "# Download the pre-trained model (this is free and runs locally)\n",
    "model_url = \"https://storage.googleapis.com/mediapipe-models/text_classifier/bert_classifier/float32/1/bert_classifier.tflite\"\n",
    "model_path = \"bert_classifier.tflite\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Downloading MediaPipe text classification model...\")\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "    print(\"Model downloaded successfully!\")\n",
    "\n",
    "# Create the text classifier\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = text.TextClassifierOptions(base_options=base_options)\n",
    "classifier = text.TextClassifier.create_from_options(options)\n",
    "\n",
    "# ========================================================\n",
    "# PART 2: Load Dataset\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading ACRA data...\")\n",
    "df = pd.read_csv(\"acra_merged_active.csv\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "if \"primary_ssic_description\" in df.columns:\n",
    "    col_name = \"primary_ssic_description\"\n",
    "elif \"primary_ssic\" in df.columns:\n",
    "    col_name = \"primary_ssic\"\n",
    "else:\n",
    "    raise ValueError(\"No SSIC description column found in CSV\")\n",
    "\n",
    "# Drop rows with empty descriptions\n",
    "df = df.dropna(subset=[col_name])\n",
    "df[col_name] = df[col_name].astype(str).str.strip()\n",
    "\n",
    "# ========================================================\n",
    "# PART 3: Updated Classification Logic with New Categories\n",
    "# ========================================================\n",
    "\n",
    "# Define comprehensive keyword mappings for Singapore context\n",
    "category_keywords = {\n",
    "    \"Emergency_services\": [\n",
    "        \"emergency\", \"ambulance\", \"fire\", \"police\", \"rescue\", \"paramedic\",\n",
    "        \"emergency medical\", \"fire station\", \"police station\", \"civil defence\",\n",
    "        \"scdf\", \"spf\", \"disaster\", \"crisis\", \"urgent care\", \"first aid\",\n",
    "        \"emergency response\", \"safety\", \"security services\", \"emergency care\"\n",
    "    ],\n",
    "    \n",
    "    \"Healthcare_facilities\": [\n",
    "        \"hospital\", \"clinic\", \"medical\", \"health\", \"dental\", \"doctor\", \"physician\",\n",
    "        \"specialist\", \"diagnostic\", \"laboratory\", \"physiotherapy\", \"tcm\",\n",
    "        \"traditional chinese medicine\", \"veterinary\", \"vet\", \"mental health\",\n",
    "        \"rehabilitation\", \"nursing\", \"healthcare\", \"medicine\", \"pharmaceutical\",\n",
    "        \"wellness\", \"therapy\", \"treatment\", \"surgery\", \"radiology\", \"dentist\",\n",
    "        \"medical center\", \"health screening\", \"pharmacy\", \"medical practice\"\n",
    "    ],\n",
    "    \n",
    "    \"Essential_services\": [\n",
    "        \"bank\", \"atm\", \"post office\", \"utility\", \"electricity\", \"water\", \"gas\",\n",
    "        \"postal\", \"singpost\", \"supermarket\", \"grocery\", \"market\", \"provision\",\n",
    "        \"convenience store\", \"pharmacy\", \"petrol\", \"fuel\", \"gas station\",\n",
    "        \"essential\", \"basic services\", \"public utilities\", \"waste management\",\n",
    "        \"recycling\", \"laundry\", \"dry cleaning\", \"repair services\"\n",
    "    ],\n",
    "    \n",
    "    \"Residential\": [\n",
    "        \"residential\", \"housing\", \"apartment\", \"condominium\", \"condo\", \"hdb\",\n",
    "        \"flat\", \"estate\", \"home\", \"house\", \"residence\", \"dwelling\", \"villa\",\n",
    "        \"bungalow\", \"townhouse\", \"maisonette\", \"penthouse\", \"serviced apartment\",\n",
    "        \"dormitory\", \"hostel\", \"boarding\", \"lodging\", \"quarters\", \"living\"\n",
    "    ],\n",
    "    \n",
    "    \"Education_institutions\": [\n",
    "        \"school\", \"education\", \"kindergarten\", \"preschool\", \"primary\", \"secondary\",\n",
    "        \"university\", \"college\", \"polytechnic\", \"institute\", \"tuition\", \"enrichment\",\n",
    "        \"training\", \"learning\", \"academic\", \"student\", \"teacher\", \"instructor\",\n",
    "        \"course\", \"class\", \"lesson\", \"workshop\", \"seminar\", \"coaching\",\n",
    "        \"educational\", \"study\", \"tutorial\", \"academy\"\n",
    "    ],\n",
    "    \n",
    "    \"Transport_services\": [\n",
    "        \"transport\", \"mrt\", \"lrt\", \"bus\", \"taxi\", \"grab\", \"station\", \"interchange\",\n",
    "        \"terminal\", \"airport\", \"changi\", \"port\", \"ferry\", \"boat\", \"marina\",\n",
    "        \"parking\", \"carpark\", \"car park\", \"garage\", \"vehicle\", \"automotive\",\n",
    "        \"workshop\", \"service center\", \"petrol station\", \"logistics\", \"courier\",\n",
    "        \"delivery\", \"shipping\", \"freight\", \"warehouse\", \"storage\"\n",
    "    ],\n",
    "    \n",
    "    \"Tourism\": [\n",
    "        \"hotel\", \"resort\", \"hostel\", \"accommodation\", \"tourist\", \"tourism\",\n",
    "        \"attraction\", \"museum\", \"gallery\", \"heritage\", \"cultural\", \"zoo\",\n",
    "        \"aquarium\", \"theme park\", \"entertainment\", \"casino\", \"cruise\",\n",
    "        \"tour\", \"travel\", \"vacation\", \"holiday\", \"sightseeing\", \"landmark\",\n",
    "        \"monument\", \"gardens\", \"park\", \"beach\", \"island\", \"sentosa\",\n",
    "        \"marina bay\", \"orchard\", \"chinatown\", \"little india\"\n",
    "    ],\n",
    "    \n",
    "    \"Community_spaces\": [\n",
    "        \"community\", \"center\", \"centre\", \"club\", \"association\", \"society\",\n",
    "        \"library\", \"sports\", \"gym\", \"fitness\", \"swimming\", \"pool\", \"court\",\n",
    "        \"field\", \"playground\", \"park\", \"garden\", \"recreational\", \"leisure\",\n",
    "        \"activity\", \"social\", \"gathering\", \"meeting\", \"event\", \"function\",\n",
    "        \"hall\", \"auditorium\", \"pavilion\", \"void deck\", \"common area\"\n",
    "    ],\n",
    "    \n",
    "    \"Government_services\": [\n",
    "        \"government\", \"ministry\", \"statutory board\", \"public\", \"civil service\",\n",
    "        \"town council\", \"hdb office\", \"cpf\", \"iras\", \"mom\", \"moe\", \"moh\",\n",
    "        \"court\", \"tribunal\", \"registry\", \"authority\", \"agency\", \"commission\",\n",
    "        \"municipal\", \"grassroots\", \"pa\", \"people's association\", \"cc\",\n",
    "        \"community center\", \"rc\", \"residents committee\", \"official\"\n",
    "    ],\n",
    "    \n",
    "    \"Retail_services\": [\n",
    "        \"retail\", \"shop\", \"store\", \"mart\", \"department store\", \"shopping\",\n",
    "        \"mall\", \"plaza\", \"fashion\", \"clothing\", \"electronics\", \"jewelry\",\n",
    "        \"jewellery\", \"hardware\", \"bookstore\", \"optical\", \"sporting goods\",\n",
    "        \"furniture\", \"toys\", \"pet\", \"beauty\", \"cosmetic\", \"salon\", \"spa\",\n",
    "        \"restaurant\", \"cafe\", \"coffee\", \"bar\", \"pub\", \"food court\", \"dining\",\n",
    "        \"catering\", \"bakery\", \"food\", \"beverage\", \"hawker\", \"entertainment\",\n",
    "        \"cinema\", \"ktv\", \"karaoke\", \"massage\", \"trading\", \"wholesale\",\n",
    "        \"import\", \"export\", \"distribution\", \"sales\", \"business\", \"commercial\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ========================================================\n",
    "# PART 4: Enhanced Classification Function\n",
    "# ========================================================\n",
    "\n",
    "def classify_business_description(description: str, use_mediapipe: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Classify business description using hybrid approach:\n",
    "    1. MediaPipe for general sentiment/category hints\n",
    "    2. Keyword matching for specific Singapore business types\n",
    "    3. Fallback logic to minimize 'Others' classification\n",
    "    \"\"\"\n",
    "    \n",
    "    description_lower = description.lower()\n",
    "    \n",
    "    # Method 1: Keyword-based classification (primary)\n",
    "    category_scores = {}\n",
    "    \n",
    "    for category, keywords in category_keywords.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in description_lower:\n",
    "                # Weight longer, more specific keywords higher\n",
    "                weight = len(keyword.split()) * 2 if len(keyword.split()) > 1 else 1\n",
    "                score += weight\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if score > 0:\n",
    "            category_scores[category] = {\n",
    "                'score': score,\n",
    "                'keywords': matched_keywords,\n",
    "                'confidence': min(score / 10.0, 1.0)  # Normalize confidence\n",
    "            }\n",
    "    \n",
    "    # Method 2: Use MediaPipe for additional insights (if available)\n",
    "    mediapipe_result = None\n",
    "    if use_mediapipe:\n",
    "        try:\n",
    "            classification_result = classifier.classify(description)\n",
    "            if classification_result.classifications:\n",
    "                # Extract top classification\n",
    "                top_classification = classification_result.classifications[0]\n",
    "                if top_classification.categories:\n",
    "                    top_category = top_classification.categories[0]\n",
    "                    mediapipe_result = {\n",
    "                        'category': top_category.category_name,\n",
    "                        'score': top_category.score\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            print(f\"MediaPipe classification error: {e}\")\n",
    "    \n",
    "    # Method 3: Smart fallback logic for common Singapore business patterns\n",
    "    if not category_scores:\n",
    "        # Try broader keyword matching\n",
    "        broad_keywords = {\n",
    "            'service': ['Essential_services', 'Retail_services'],\n",
    "            'services': ['Essential_services', 'Retail_services'],\n",
    "            'company': ['Retail_services', 'Essential_services'],\n",
    "            'center': ['Community_spaces', 'Healthcare_facilities'],\n",
    "            'centre': ['Community_spaces', 'Healthcare_facilities'],\n",
    "            'management': ['Retail_services', 'Essential_services'],\n",
    "            'trading': ['Retail_services'],\n",
    "            'engineering': ['Essential_services'],\n",
    "            'development': ['Retail_services'],\n",
    "            'construction': ['Essential_services'],\n",
    "            'technology': ['Retail_services'],\n",
    "            'consulting': ['Retail_services'],\n",
    "            'solutions': ['Retail_services'],\n",
    "            'systems': ['Retail_services'],\n",
    "            'international': ['Retail_services'],\n",
    "            'industrial': ['Essential_services'],\n",
    "            'manufacturing': ['Essential_services']\n",
    "        }\n",
    "        \n",
    "        for keyword, potential_categories in broad_keywords.items():\n",
    "            if keyword in description_lower:\n",
    "                # Assign to most likely category with lower confidence\n",
    "                category_scores[potential_categories[0]] = {\n",
    "                    'score': 1,\n",
    "                    'keywords': [keyword],\n",
    "                    'confidence': 0.4\n",
    "                }\n",
    "                break\n",
    "    \n",
    "    # Final decision logic\n",
    "    if category_scores:\n",
    "        # Get category with highest score\n",
    "        best_category = max(category_scores.items(), key=lambda x: x[1]['score'])\n",
    "        \n",
    "        primary_category = best_category[0]\n",
    "        confidence = best_category[1]['confidence']\n",
    "        keywords_matched = best_category[1]['keywords']\n",
    "        \n",
    "        # Get secondary categories if they exist\n",
    "        secondary_categories = [cat for cat, data in category_scores.items() \n",
    "                             if cat != primary_category and data['score'] >= 2]\n",
    "        \n",
    "        all_categories = [primary_category] + secondary_categories[:2]  # Max 3 categories\n",
    "        \n",
    "        return all_categories, confidence, keywords_matched\n",
    "    \n",
    "    else:\n",
    "        # Last resort: default to Others\n",
    "        return ['Others'], 0.2, ['no_keywords_matched']\n",
    "\n",
    "# ========================================================\n",
    "# PART 5: Apply Classification to Dataset\n",
    "# ========================================================\n",
    "\n",
    "print(\"Starting enhanced classification with new categories...\")\n",
    "\n",
    "# Process sample first\n",
    "df_sample = df.head(3000)  # Test with 3k records\n",
    "print(f\"Processing {len(df_sample)} records...\")\n",
    "\n",
    "results = []\n",
    "for desc in tqdm(df_sample[col_name].astype(str).tolist(), desc=\"Classifying\"):\n",
    "    result = classify_business_description(desc)\n",
    "    results.append(result)\n",
    "\n",
    "# Unpack results\n",
    "categories_list, confidences, keywords_matched = zip(*results)\n",
    "\n",
    "df_sample['amenity_categories'] = [', '.join(cats) for cats in categories_list]\n",
    "df_sample['classification_confidence'] = confidences\n",
    "df_sample['keywords_matched'] = [', '.join(kw) for kw in keywords_matched]\n",
    "\n",
    "# ========================================================\n",
    "# PART 6: Save Results and Analysis\n",
    "# ========================================================\n",
    "\n",
    "output_path = \"acra_classified_new_categories.csv\"\n",
    "df_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nClassification complete! Results saved to {output_path}\")\n",
    "\n",
    "# ========================================================\n",
    "# PART 7: Detailed Analysis\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEW CATEGORY CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Category distribution\n",
    "category_counts = (\n",
    "    df_sample['amenity_categories']\n",
    "    .str.split(', ')\n",
    "    .explode()\n",
    "    .value_counts()\n",
    ")\n",
    "\n",
    "print(f\"\\nCategory Distribution:\")\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(df_sample)) * 100\n",
    "    print(f\"{category:25}: {count:4d} ({percentage:5.1f}%)\")\n",
    "\n",
    "# Key improvements\n",
    "others_pct = (category_counts.get('Others', 0) / len(df_sample)) * 100\n",
    "print(f\"\\n🎯 'Others' percentage: {others_pct:.1f}%\")\n",
    "\n",
    "# Confidence analysis\n",
    "high_conf = len(df_sample[df_sample['classification_confidence'] >= 0.7])\n",
    "medium_conf = len(df_sample[(df_sample['classification_confidence'] >= 0.4) & \n",
    "                           (df_sample['classification_confidence'] < 0.7)])\n",
    "low_conf = len(df_sample[df_sample['classification_confidence'] < 0.4])\n",
    "\n",
    "print(f\"\\nConfidence Distribution:\")\n",
    "print(f\"High confidence (≥0.7): {high_conf} ({high_conf/len(df_sample)*100:.1f}%)\")\n",
    "print(f\"Medium confidence (0.4-0.7): {medium_conf} ({medium_conf/len(df_sample)*100:.1f}%)\")\n",
    "print(f\"Low confidence (<0.4): {low_conf} ({low_conf/len(df_sample)*100:.1f}%)\")\n",
    "\n",
    "# Sample results\n",
    "print(f\"\\nSample Results:\")\n",
    "print(\"-\" * 120)\n",
    "for idx in range(min(15, len(df_sample))):\n",
    "    row = df_sample.iloc[idx]\n",
    "    desc = row[col_name][:50] + \"...\" if len(row[col_name]) > 50 else row[col_name]\n",
    "    print(f\"Business: {desc:52} → {row['amenity_categories']:25} \"\n",
    "          f\"({row['classification_confidence']:.2f}) [{row['keywords_matched'][:30]}]\")\n",
    "\n",
    "print(f\"\\n✅ SUCCESS! Classification completed with new category structure!\")\n",
    "print(f\"📊 Processed: {len(df_sample)} records\")\n",
    "print(f\"📁 Saved to: {output_path}\")\n",
    "\n",
    "# Expected category breakdown for full 950k dataset prediction\n",
    "print(f\"\\n🔮 PREDICTION FOR FULL 950K DATASET:\")\n",
    "print(\"Based on current sample performance:\")\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(df_sample)) * 100\n",
    "    predicted_full = int((percentage / 100) * 950000)\n",
    "    print(f\"{category:25}: ~{predicted_full:,} records ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c61f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MediaPipe Text Classifier...\n",
      "Loading ACRA data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757133725.268761 1045667 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2\n",
      "W0000 00:00:1757133725.316120 1069728 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (951620, 15)\n",
      "Starting enhanced classification with new categories...\n",
      "Processing 951,620 records in 96 batches of 10,000 records each...\n",
      "\n",
      "--- Processing Batch 1/96 ---\n",
      "Records 0 to 9,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1/96: 100%|██████████| 10000/10000 [04:32<00:00, 36.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new file: acra_classified_full_dataset.csv\n",
      "Batch 1 'Others' percentage: 7.4%\n",
      "\n",
      "--- Processing Batch 2/96 ---\n",
      "Records 10,000 to 19,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2/96: 100%|██████████| 10000/10000 [04:30<00:00, 36.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 2 to acra_classified_full_dataset.csv\n",
      "Batch 2 'Others' percentage: 6.7%\n",
      "\n",
      "--- Processing Batch 3/96 ---\n",
      "Records 20,000 to 29,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3/96: 100%|██████████| 10000/10000 [04:32<00:00, 36.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 3 to acra_classified_full_dataset.csv\n",
      "Batch 3 'Others' percentage: 12.3%\n",
      "\n",
      "--- Processing Batch 4/96 ---\n",
      "Records 30,000 to 39,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4/96: 100%|██████████| 10000/10000 [04:36<00:00, 36.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 4 to acra_classified_full_dataset.csv\n",
      "Batch 4 'Others' percentage: 7.8%\n",
      "\n",
      "--- Processing Batch 5/96 ---\n",
      "Records 40,000 to 49,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5/96: 100%|██████████| 10000/10000 [04:35<00:00, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 5 to acra_classified_full_dataset.csv\n",
      "Batch 5 'Others' percentage: 8.8%\n",
      "\n",
      "--- Processing Batch 6/96 ---\n",
      "Records 50,000 to 59,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6/96: 100%|██████████| 10000/10000 [04:30<00:00, 37.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 6 to acra_classified_full_dataset.csv\n",
      "Batch 6 'Others' percentage: 6.8%\n",
      "\n",
      "--- Processing Batch 7/96 ---\n",
      "Records 60,000 to 69,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7/96: 100%|██████████| 10000/10000 [04:29<00:00, 37.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 7 to acra_classified_full_dataset.csv\n",
      "Batch 7 'Others' percentage: 9.1%\n",
      "\n",
      "--- Processing Batch 8/96 ---\n",
      "Records 70,000 to 79,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 8/96: 100%|██████████| 10000/10000 [04:31<00:00, 36.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 8 to acra_classified_full_dataset.csv\n",
      "Batch 8 'Others' percentage: 10.4%\n",
      "\n",
      "--- Processing Batch 9/96 ---\n",
      "Records 80,000 to 89,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 9/96: 100%|██████████| 10000/10000 [04:30<00:00, 36.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 9 to acra_classified_full_dataset.csv\n",
      "Batch 9 'Others' percentage: 7.9%\n",
      "\n",
      "--- Processing Batch 10/96 ---\n",
      "Records 90,000 to 99,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 10/96: 100%|██████████| 10000/10000 [04:32<00:00, 36.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 10 to acra_classified_full_dataset.csv\n",
      "Batch 10 'Others' percentage: 8.8%\n",
      "\n",
      "--- Processing Batch 11/96 ---\n",
      "Records 100,000 to 109,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 11/96: 100%|██████████| 10000/10000 [04:27<00:00, 37.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 11 to acra_classified_full_dataset.csv\n",
      "Batch 11 'Others' percentage: 7.0%\n",
      "\n",
      "--- Processing Batch 12/96 ---\n",
      "Records 110,000 to 119,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 12/96: 100%|██████████| 10000/10000 [04:29<00:00, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 12 to acra_classified_full_dataset.csv\n",
      "Batch 12 'Others' percentage: 6.8%\n",
      "\n",
      "--- Processing Batch 13/96 ---\n",
      "Records 120,000 to 129,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 13/96: 100%|██████████| 10000/10000 [04:24<00:00, 37.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 13 to acra_classified_full_dataset.csv\n",
      "Batch 13 'Others' percentage: 6.7%\n",
      "\n",
      "--- Processing Batch 14/96 ---\n",
      "Records 130,000 to 139,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 14/96: 100%|██████████| 10000/10000 [04:38<00:00, 35.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 14 to acra_classified_full_dataset.csv\n",
      "Batch 14 'Others' percentage: 11.3%\n",
      "\n",
      "--- Processing Batch 15/96 ---\n",
      "Records 140,000 to 149,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 15/96: 100%|██████████| 10000/10000 [04:32<00:00, 36.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 15 to acra_classified_full_dataset.csv\n",
      "Batch 15 'Others' percentage: 10.5%\n",
      "\n",
      "--- Processing Batch 16/96 ---\n",
      "Records 150,000 to 159,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 16/96: 100%|██████████| 10000/10000 [04:59<00:00, 33.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 16 to acra_classified_full_dataset.csv\n",
      "Batch 16 'Others' percentage: 9.0%\n",
      "\n",
      "--- Processing Batch 17/96 ---\n",
      "Records 160,000 to 169,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 17/96: 100%|██████████| 10000/10000 [04:43<00:00, 35.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 17 to acra_classified_full_dataset.csv\n",
      "Batch 17 'Others' percentage: 8.0%\n",
      "\n",
      "--- Processing Batch 18/96 ---\n",
      "Records 170,000 to 179,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 18/96: 100%|██████████| 10000/10000 [04:54<00:00, 34.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 18 to acra_classified_full_dataset.csv\n",
      "Batch 18 'Others' percentage: 9.7%\n",
      "\n",
      "--- Processing Batch 19/96 ---\n",
      "Records 180,000 to 189,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 19/96: 100%|██████████| 10000/10000 [04:32<00:00, 36.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 19 to acra_classified_full_dataset.csv\n",
      "Batch 19 'Others' percentage: 7.0%\n",
      "\n",
      "--- Processing Batch 20/96 ---\n",
      "Records 190,000 to 199,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 20/96: 100%|██████████| 10000/10000 [04:35<00:00, 36.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 20 to acra_classified_full_dataset.csv\n",
      "Batch 20 'Others' percentage: 6.5%\n",
      "\n",
      "--- Processing Batch 21/96 ---\n",
      "Records 200,000 to 209,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 21/96: 100%|██████████| 10000/10000 [05:02<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 21 to acra_classified_full_dataset.csv\n",
      "Batch 21 'Others' percentage: 9.7%\n",
      "\n",
      "--- Processing Batch 22/96 ---\n",
      "Records 210,000 to 219,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 22/96: 100%|██████████| 10000/10000 [04:37<00:00, 36.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 22 to acra_classified_full_dataset.csv\n",
      "Batch 22 'Others' percentage: 14.4%\n",
      "\n",
      "--- Processing Batch 23/96 ---\n",
      "Records 220,000 to 229,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 23/96: 100%|██████████| 10000/10000 [04:40<00:00, 35.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 23 to acra_classified_full_dataset.csv\n",
      "Batch 23 'Others' percentage: 10.3%\n",
      "\n",
      "--- Processing Batch 24/96 ---\n",
      "Records 230,000 to 239,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 24/96: 100%|██████████| 10000/10000 [06:27<00:00, 25.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 24 to acra_classified_full_dataset.csv\n",
      "Batch 24 'Others' percentage: 8.6%\n",
      "\n",
      "--- Processing Batch 25/96 ---\n",
      "Records 240,000 to 249,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 25/96: 100%|██████████| 10000/10000 [14:56<00:00, 11.16it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 25 to acra_classified_full_dataset.csv\n",
      "Batch 25 'Others' percentage: 8.8%\n",
      "\n",
      "--- Processing Batch 26/96 ---\n",
      "Records 250,000 to 259,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 26/96: 100%|██████████| 10000/10000 [31:45<00:00,  5.25it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 26 to acra_classified_full_dataset.csv\n",
      "Batch 26 'Others' percentage: 10.1%\n",
      "\n",
      "--- Processing Batch 27/96 ---\n",
      "Records 260,000 to 269,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 27/96: 100%|██████████| 10000/10000 [21:32<00:00,  7.74it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 27 to acra_classified_full_dataset.csv\n",
      "Batch 27 'Others' percentage: 10.6%\n",
      "\n",
      "--- Processing Batch 28/96 ---\n",
      "Records 270,000 to 279,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 28/96: 100%|██████████| 10000/10000 [12:25<00:00, 13.41it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 28 to acra_classified_full_dataset.csv\n",
      "Batch 28 'Others' percentage: 8.3%\n",
      "\n",
      "--- Processing Batch 29/96 ---\n",
      "Records 280,000 to 289,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 29/96: 100%|██████████| 10000/10000 [04:38<00:00, 35.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 29 to acra_classified_full_dataset.csv\n",
      "Batch 29 'Others' percentage: 8.0%\n",
      "\n",
      "--- Processing Batch 30/96 ---\n",
      "Records 290,000 to 299,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 30/96: 100%|██████████| 10000/10000 [04:32<00:00, 36.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 30 to acra_classified_full_dataset.csv\n",
      "Batch 30 'Others' percentage: 10.4%\n",
      "\n",
      "--- Processing Batch 31/96 ---\n",
      "Records 300,000 to 309,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 31/96: 100%|██████████| 10000/10000 [07:32<00:00, 22.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 31 to acra_classified_full_dataset.csv\n",
      "Batch 31 'Others' percentage: 8.1%\n",
      "\n",
      "--- Processing Batch 32/96 ---\n",
      "Records 310,000 to 319,999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 32/96:   0%|          | 14/10000 [00:00<06:49, 24.38it/s]"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# ACRA Amenity Classification with MediaPipe Text Classifier\n",
    "# Updated Categories: Emergency, Healthcare, Essential, Residential, Education, \n",
    "# Transport, Tourism, Community, Government, Retail, Others\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import text\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# ========================================================\n",
    "# PART 1: Setup MediaPipe Text Classifier\n",
    "# ========================================================\n",
    "\n",
    "print(\"Setting up MediaPipe Text Classifier...\")\n",
    "\n",
    "# Download the pre-trained model (this is free and runs locally)\n",
    "model_url = \"https://storage.googleapis.com/mediapipe-models/text_classifier/bert_classifier/float32/1/bert_classifier.tflite\"\n",
    "model_path = \"bert_classifier.tflite\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Downloading MediaPipe text classification model...\")\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "    print(\"Model downloaded successfully!\")\n",
    "\n",
    "# Create the text classifier\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = text.TextClassifierOptions(base_options=base_options)\n",
    "classifier = text.TextClassifier.create_from_options(options)\n",
    "\n",
    "# ========================================================\n",
    "# PART 2: Load Dataset\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading ACRA data...\")\n",
    "df = pd.read_csv(\"acra_merged_active.csv\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "if \"primary_ssic_description\" in df.columns:\n",
    "    col_name = \"primary_ssic_description\"\n",
    "elif \"primary_ssic\" in df.columns:\n",
    "    col_name = \"primary_ssic\"\n",
    "else:\n",
    "    raise ValueError(\"No SSIC description column found in CSV\")\n",
    "\n",
    "# Drop rows with empty descriptions\n",
    "df = df.dropna(subset=[col_name])\n",
    "df[col_name] = df[col_name].astype(str).str.strip()\n",
    "\n",
    "# ========================================================\n",
    "# PART 3: Updated Classification Logic with New Categories\n",
    "# ========================================================\n",
    "\n",
    "# Define comprehensive keyword mappings for Singapore context\n",
    "category_keywords = {\n",
    "    \"Emergency_services\": [\n",
    "        \"emergency\", \"ambulance\", \"fire\", \"police\", \"rescue\", \"paramedic\",\n",
    "        \"emergency medical\", \"fire station\", \"police station\", \"civil defence\",\n",
    "        \"scdf\", \"spf\", \"disaster\", \"crisis\", \"urgent care\", \"first aid\",\n",
    "        \"emergency response\", \"safety\", \"security services\", \"emergency care\"\n",
    "    ],\n",
    "    \n",
    "    \"Healthcare_facilities\": [\n",
    "        \"hospital\", \"clinic\", \"medical\", \"health\", \"dental\", \"doctor\", \"physician\",\n",
    "        \"specialist\", \"diagnostic\", \"laboratory\", \"physiotherapy\", \"tcm\",\n",
    "        \"traditional chinese medicine\", \"veterinary\", \"vet\", \"mental health\",\n",
    "        \"rehabilitation\", \"nursing\", \"healthcare\", \"medicine\", \"pharmaceutical\",\n",
    "        \"wellness\", \"therapy\", \"treatment\", \"surgery\", \"radiology\", \"dentist\",\n",
    "        \"medical center\", \"health screening\", \"pharmacy\", \"medical practice\"\n",
    "    ],\n",
    "    \n",
    "    \"Essential_services\": [\n",
    "        \"bank\", \"atm\", \"post office\", \"utility\", \"electricity\", \"water\", \"gas\",\n",
    "        \"postal\", \"singpost\", \"supermarket\", \"grocery\", \"market\", \"provision\",\n",
    "        \"convenience store\", \"pharmacy\", \"petrol\", \"fuel\", \"gas station\",\n",
    "        \"essential\", \"basic services\", \"public utilities\", \"waste management\",\n",
    "        \"recycling\", \"laundry\", \"dry cleaning\", \"repair services\"\n",
    "    ],\n",
    "    \n",
    "    \"Residential\": [\n",
    "        \"residential\", \"housing\", \"apartment\", \"condominium\", \"condo\", \"hdb\",\n",
    "        \"flat\", \"estate\", \"home\", \"house\", \"residence\", \"dwelling\", \"villa\",\n",
    "        \"bungalow\", \"townhouse\", \"maisonette\", \"penthouse\", \"serviced apartment\",\n",
    "        \"dormitory\", \"hostel\", \"boarding\", \"lodging\", \"quarters\", \"living\"\n",
    "    ],\n",
    "    \n",
    "    \"Education_institutions\": [\n",
    "        \"school\", \"education\", \"kindergarten\", \"preschool\", \"primary\", \"secondary\",\n",
    "        \"university\", \"college\", \"polytechnic\", \"institute\", \"tuition\", \"enrichment\",\n",
    "        \"training\", \"learning\", \"academic\", \"student\", \"teacher\", \"instructor\",\n",
    "        \"course\", \"class\", \"lesson\", \"workshop\", \"seminar\", \"coaching\",\n",
    "        \"educational\", \"study\", \"tutorial\", \"academy\"\n",
    "    ],\n",
    "    \n",
    "    \"Transport_services\": [\n",
    "        \"transport\", \"mrt\", \"lrt\", \"bus\", \"taxi\", \"grab\", \"station\", \"interchange\",\n",
    "        \"terminal\", \"airport\", \"changi\", \"port\", \"ferry\", \"boat\", \"marina\",\n",
    "        \"parking\", \"carpark\", \"car park\", \"garage\", \"vehicle\", \"automotive\",\n",
    "        \"workshop\", \"service center\", \"petrol station\", \"logistics\", \"courier\",\n",
    "        \"delivery\", \"shipping\", \"freight\", \"warehouse\", \"storage\"\n",
    "    ],\n",
    "    \n",
    "    \"Tourism\": [\n",
    "        \"hotel\", \"resort\", \"hostel\", \"accommodation\", \"tourist\", \"tourism\",\n",
    "        \"attraction\", \"museum\", \"gallery\", \"heritage\", \"cultural\", \"zoo\",\n",
    "        \"aquarium\", \"theme park\", \"entertainment\", \"casino\", \"cruise\",\n",
    "        \"tour\", \"travel\", \"vacation\", \"holiday\", \"sightseeing\", \"landmark\",\n",
    "        \"monument\", \"gardens\", \"park\", \"beach\", \"island\", \"sentosa\",\n",
    "        \"marina bay\", \"orchard\", \"chinatown\", \"little india\"\n",
    "    ],\n",
    "    \n",
    "    \"Community_spaces\": [\n",
    "        \"community\", \"center\", \"centre\", \"club\", \"association\", \"society\",\n",
    "        \"library\", \"sports\", \"gym\", \"fitness\", \"swimming\", \"pool\", \"court\",\n",
    "        \"field\", \"playground\", \"park\", \"garden\", \"recreational\", \"leisure\",\n",
    "        \"activity\", \"social\", \"gathering\", \"meeting\", \"event\", \"function\",\n",
    "        \"hall\", \"auditorium\", \"pavilion\", \"void deck\", \"common area\"\n",
    "    ],\n",
    "    \n",
    "    \"Government_services\": [\n",
    "        \"government\", \"ministry\", \"statutory board\", \"public\", \"civil service\",\n",
    "        \"town council\", \"hdb office\", \"cpf\", \"iras\", \"mom\", \"moe\", \"moh\",\n",
    "        \"court\", \"tribunal\", \"registry\", \"authority\", \"agency\", \"commission\",\n",
    "        \"municipal\", \"grassroots\", \"pa\", \"people's association\", \"cc\",\n",
    "        \"community center\", \"rc\", \"residents committee\", \"official\"\n",
    "    ],\n",
    "    \n",
    "    \"Retail_services\": [\n",
    "        \"retail\", \"shop\", \"store\", \"mart\", \"department store\", \"shopping\",\n",
    "        \"mall\", \"plaza\", \"fashion\", \"clothing\", \"electronics\", \"jewelry\",\n",
    "        \"jewellery\", \"hardware\", \"bookstore\", \"optical\", \"sporting goods\",\n",
    "        \"furniture\", \"toys\", \"pet\", \"beauty\", \"cosmetic\", \"salon\", \"spa\",\n",
    "        \"restaurant\", \"cafe\", \"coffee\", \"bar\", \"pub\", \"food court\", \"dining\",\n",
    "        \"catering\", \"bakery\", \"food\", \"beverage\", \"hawker\", \"entertainment\",\n",
    "        \"cinema\", \"ktv\", \"karaoke\", \"massage\", \"trading\", \"wholesale\",\n",
    "        \"import\", \"export\", \"distribution\", \"sales\", \"business\", \"commercial\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ========================================================\n",
    "# PART 4: Enhanced Classification Function\n",
    "# ========================================================\n",
    "\n",
    "def classify_business_description(description: str, use_mediapipe: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Classify business description using hybrid approach:\n",
    "    1. MediaPipe for general sentiment/category hints\n",
    "    2. Keyword matching for specific Singapore business types\n",
    "    3. Fallback logic to minimize 'Others' classification\n",
    "    \"\"\"\n",
    "    \n",
    "    description_lower = description.lower()\n",
    "    \n",
    "    # Method 1: Keyword-based classification (primary)\n",
    "    category_scores = {}\n",
    "    \n",
    "    for category, keywords in category_keywords.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in description_lower:\n",
    "                # Weight longer, more specific keywords higher\n",
    "                weight = len(keyword.split()) * 2 if len(keyword.split()) > 1 else 1\n",
    "                score += weight\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if score > 0:\n",
    "            category_scores[category] = {\n",
    "                'score': score,\n",
    "                'keywords': matched_keywords,\n",
    "                'confidence': min(score / 10.0, 1.0)  # Normalize confidence\n",
    "            }\n",
    "    \n",
    "    # Method 2: Use MediaPipe for additional insights (if available)\n",
    "    mediapipe_result = None\n",
    "    if use_mediapipe:\n",
    "        try:\n",
    "            classification_result = classifier.classify(description)\n",
    "            if classification_result.classifications:\n",
    "                # Extract top classification\n",
    "                top_classification = classification_result.classifications[0]\n",
    "                if top_classification.categories:\n",
    "                    top_category = top_classification.categories[0]\n",
    "                    mediapipe_result = {\n",
    "                        'category': top_category.category_name,\n",
    "                        'score': top_category.score\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            print(f\"MediaPipe classification error: {e}\")\n",
    "    \n",
    "    # Method 3: Smart fallback logic for common Singapore business patterns\n",
    "    if not category_scores:\n",
    "        # Try broader keyword matching\n",
    "        broad_keywords = {\n",
    "            'service': ['Essential_services', 'Retail_services'],\n",
    "            'services': ['Essential_services', 'Retail_services'],\n",
    "            'company': ['Retail_services', 'Essential_services'],\n",
    "            'center': ['Community_spaces', 'Healthcare_facilities'],\n",
    "            'centre': ['Community_spaces', 'Healthcare_facilities'],\n",
    "            'management': ['Retail_services', 'Essential_services'],\n",
    "            'trading': ['Retail_services'],\n",
    "            'engineering': ['Essential_services'],\n",
    "            'development': ['Retail_services'],\n",
    "            'construction': ['Essential_services'],\n",
    "            'technology': ['Retail_services'],\n",
    "            'consulting': ['Retail_services'],\n",
    "            'solutions': ['Retail_services'],\n",
    "            'systems': ['Retail_services'],\n",
    "            'international': ['Retail_services'],\n",
    "            'industrial': ['Essential_services'],\n",
    "            'manufacturing': ['Essential_services']\n",
    "        }\n",
    "        \n",
    "        for keyword, potential_categories in broad_keywords.items():\n",
    "            if keyword in description_lower:\n",
    "                # Assign to most likely category with lower confidence\n",
    "                category_scores[potential_categories[0]] = {\n",
    "                    'score': 1,\n",
    "                    'keywords': [keyword],\n",
    "                    'confidence': 0.4\n",
    "                }\n",
    "                break\n",
    "    \n",
    "    # Final decision logic\n",
    "    if category_scores:\n",
    "        # Get category with highest score\n",
    "        best_category = max(category_scores.items(), key=lambda x: x[1]['score'])\n",
    "        \n",
    "        primary_category = best_category[0]\n",
    "        confidence = best_category[1]['confidence']\n",
    "        keywords_matched = best_category[1]['keywords']\n",
    "        \n",
    "        # Get secondary categories if they exist\n",
    "        secondary_categories = [cat for cat, data in category_scores.items() \n",
    "                             if cat != primary_category and data['score'] >= 2]\n",
    "        \n",
    "        all_categories = [primary_category] + secondary_categories[:2]  # Max 3 categories\n",
    "        \n",
    "        return all_categories, confidence, keywords_matched\n",
    "    \n",
    "    else:\n",
    "        # Last resort: default to Others\n",
    "        return ['Others'], 0.2, ['no_keywords_matched']\n",
    "\n",
    "# ========================================================\n",
    "# PART 5: Apply Classification to Dataset (Batch Processing)\n",
    "# ========================================================\n",
    "\n",
    "print(\"Starting enhanced classification with new categories...\")\n",
    "\n",
    "# Batch processing configuration\n",
    "BATCH_SIZE = 10000\n",
    "total_records = len(df)\n",
    "num_batches = (total_records + BATCH_SIZE - 1) // BATCH_SIZE  # Ceiling division\n",
    "output_path = \"acra_classified_full_dataset.csv\"\n",
    "\n",
    "print(f\"Processing {total_records:,} records in {num_batches} batches of {BATCH_SIZE:,} records each...\")\n",
    "\n",
    "# Process in batches\n",
    "for batch_num in range(num_batches):\n",
    "    start_idx = batch_num * BATCH_SIZE\n",
    "    end_idx = min((batch_num + 1) * BATCH_SIZE, total_records)\n",
    "    \n",
    "    print(f\"\\n--- Processing Batch {batch_num + 1}/{num_batches} ---\")\n",
    "    print(f\"Records {start_idx:,} to {end_idx-1:,}\")\n",
    "    \n",
    "    # Get current batch\n",
    "    df_batch = df.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    # Process batch\n",
    "    results = []\n",
    "    for desc in tqdm(df_batch[col_name].astype(str).tolist(), \n",
    "                     desc=f\"Batch {batch_num + 1}/{num_batches}\"):\n",
    "        result = classify_business_description(desc)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Unpack results\n",
    "    categories_list, confidences, keywords_matched = zip(*results)\n",
    "    \n",
    "    df_batch['amenity_categories'] = [', '.join(cats) for cats in categories_list]\n",
    "    df_batch['classification_confidence'] = confidences\n",
    "    df_batch['keywords_matched'] = [', '.join(kw) for kw in keywords_matched]\n",
    "    \n",
    "    # Save batch results (append to CSV)\n",
    "    if batch_num == 0:\n",
    "        # First batch - create new file with headers\n",
    "        df_batch.to_csv(output_path, index=False, mode='w')\n",
    "        print(f\"Created new file: {output_path}\")\n",
    "    else:\n",
    "        # Subsequent batches - append without headers\n",
    "        df_batch.to_csv(output_path, index=False, mode='a', header=False)\n",
    "        print(f\"Appended batch {batch_num + 1} to {output_path}\")\n",
    "    \n",
    "    # Quick batch analysis\n",
    "    batch_category_counts = (\n",
    "        df_batch['amenity_categories']\n",
    "        .str.split(', ')\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "    )\n",
    "    \n",
    "    batch_others_pct = (batch_category_counts.get('Others', 0) / len(df_batch)) * 100\n",
    "    print(f\"Batch {batch_num + 1} 'Others' percentage: {batch_others_pct:.1f}%\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    del df_batch, results, categories_list, confidences, keywords_matched\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\n🎉 ALL BATCHES COMPLETE! Full dataset processed and saved to {output_path}\")\n",
    "\n",
    "# ========================================================\n",
    "# PART 6: Final Analysis (Read back the complete results)\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\nReading complete results for final analysis...\")\n",
    "try:\n",
    "    df_final = pd.read_csv(output_path)\n",
    "    print(f\"Successfully loaded {len(df_final):,} processed records from {output_path}\")\n",
    "    \n",
    "    # ========================================================\n",
    "    # PART 7: Detailed Analysis\n",
    "    # ========================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION RESULTS - FULL DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Category distribution\n",
    "    category_counts = (\n",
    "        df_final['amenity_categories']\n",
    "        .str.split(', ')\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCategory Distribution:\")\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df_final)) * 100\n",
    "        print(f\"{category:25}: {count:,} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Key improvements\n",
    "    others_pct = (category_counts.get('Others', 0) / len(df_final)) * 100\n",
    "    print(f\"\\n🎯 'Others' percentage: {others_pct:.1f}%\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    high_conf = len(df_final[df_final['classification_confidence'] >= 0.7])\n",
    "    medium_conf = len(df_final[(df_final['classification_confidence'] >= 0.4) & \n",
    "                               (df_final['classification_confidence'] < 0.7)])\n",
    "    low_conf = len(df_final[df_final['classification_confidence'] < 0.4])\n",
    "    \n",
    "    print(f\"\\nConfidence Distribution:\")\n",
    "    print(f\"High confidence (≥0.7): {high_conf:,} ({high_conf/len(df_final)*100:.1f}%)\")\n",
    "    print(f\"Medium confidence (0.4-0.7): {medium_conf:,} ({medium_conf/len(df_final)*100:.1f}%)\")\n",
    "    print(f\"Low confidence (<0.4): {low_conf:,} ({low_conf/len(df_final)*100:.1f}%)\")\n",
    "    \n",
    "    # Sample results\n",
    "    print(f\"\\nSample Results (first 15 records):\")\n",
    "    print(\"-\" * 120)\n",
    "    for idx in range(min(15, len(df_final))):\n",
    "        row = df_final.iloc[idx]\n",
    "        desc = row[col_name][:50] + \"...\" if len(row[col_name]) > 50 else row[col_name]\n",
    "        print(f\"Business: {desc:52} → {row['amenity_categories']:25} \"\n",
    "              f\"({row['classification_confidence']:.2f}) [{row['keywords_matched'][:30]}]\")\n",
    "    \n",
    "    print(f\"\\n✅ SUCCESS! Classification completed on FULL DATASET!\")\n",
    "    print(f\"📊 Total processed: {len(df_final):,} records\")\n",
    "    print(f\"📁 Results saved to: {output_path}\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n🔮 FINAL RESULTS SUMMARY:\")\n",
    "    print(f\"Total records processed: {len(df_final):,}\")\n",
    "    print(f\"'Others' category: {others_pct:.1f}% ({category_counts.get('Others', 0):,} records)\")\n",
    "    print(f\"Successfully classified: {100 - others_pct:.1f}%\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Could not find {output_path} for final analysis.\")\n",
    "    print(\"The batch processing should have created this file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading final results: {e}\")\n",
    "    print(\"Final analysis could not be completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf0c3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIAGNOSTIC CHECK ===\n",
      "✅ Dataset loaded: 951,620 rows, 15 columns\n",
      "Columns: ['uen', 'entity_name', 'entity_status_description', 'block', 'street_name', 'level_no', 'unit_no', 'building_name', 'postal_code', 'primary_ssic_code', 'primary_ssic_description', 'primary_user_described_activity', 'secondary_ssic_code', 'secondary_ssic_description', 'secondary_user_described_activity']\n",
      "✅ Found column: primary_ssic_description\n",
      "Null values in primary_ssic_description: 0\n",
      "✅ After dropping nulls: 951,620 rows\n",
      "\n",
      "Sample descriptions:\n",
      "1. RETAIL SALE OF JEWELLERY MADE FROM PRECIOUS METALS AND STONES...\n",
      "2. WHOLESALE OF LIVESTOCK, MEAT, POULTRY, EGGS AND SEAFOOD (INCLUDING FRESH AND FROZEN)...\n",
      "3. FUNERAL AND RELATED ACTIVITIES (INCLUDING EMBALMING, CREMATING AND CEMETERY SERVICES, UPKEEP OF CEME...\n",
      "4. MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS...\n",
      "5. MANUFACTURE OF SOAP, DETERGENTS, WASHING AND OTHER CLEANING PREPARATIONS...\n",
      "\n",
      "=== CHECKING EXISTING OUTPUT FILES ===\n",
      "✅ acra_classified_full_dataset.csv: 370,000 records\n",
      "⭕ acra_classified_part2.csv: Does not exist\n",
      "⭕ acra_classified_part3.csv: Does not exist\n",
      "\n",
      "=== DIAGNOSIS COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"=== DIAGNOSTIC CHECK ===\")\n",
    "\n",
    "# Check if the main CSV file exists and is readable\n",
    "try:\n",
    "    df = pd.read_csv(\"acra_merged_active.csv\")\n",
    "    print(f\"✅ Dataset loaded: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Check for the SSIC column\n",
    "    if \"primary_ssic_description\" in df.columns:\n",
    "        col_name = \"primary_ssic_description\"\n",
    "        print(f\"✅ Found column: {col_name}\")\n",
    "    elif \"primary_ssic\" in df.columns:\n",
    "        col_name = \"primary_ssic\"\n",
    "        print(f\"✅ Found column: {col_name}\")\n",
    "    else:\n",
    "        print(\"❌ No SSIC description column found!\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        exit()\n",
    "    \n",
    "    # Check for null values\n",
    "    null_count = df[col_name].isnull().sum()\n",
    "    print(f\"Null values in {col_name}: {null_count:,}\")\n",
    "    \n",
    "    # Check data after dropping nulls\n",
    "    df_clean = df.dropna(subset=[col_name])\n",
    "    print(f\"✅ After dropping nulls: {len(df_clean):,} rows\")\n",
    "    \n",
    "    # Sample the data\n",
    "    print(f\"\\nSample descriptions:\")\n",
    "    for i in range(min(5, len(df_clean))):\n",
    "        desc = str(df_clean.iloc[i][col_name])\n",
    "        print(f\"{i+1}. {desc[:100]}...\")\n",
    "    \n",
    "    print(\"\\n=== CHECKING EXISTING OUTPUT FILES ===\")\n",
    "    \n",
    "    # Check existing output files\n",
    "    output_files = [\n",
    "        \"acra_classified_full_dataset.csv\",\n",
    "        \"acra_classified_part2.csv\", \n",
    "        \"acra_classified_part3.csv\"\n",
    "    ]\n",
    "    \n",
    "    for file_path in output_files:\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df_existing = pd.read_csv(file_path)\n",
    "                print(f\"✅ {file_path}: {len(df_existing):,} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {file_path}: Error reading - {e}\")\n",
    "        else:\n",
    "            print(f\"⭕ {file_path}: Does not exist\")\n",
    "    \n",
    "    print(\"\\n=== DIAGNOSIS COMPLETE ===\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c4d735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MediaPipe Text Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757151264.463498   15117 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2\n",
      "W0000 00:00:1757151264.677622   42381 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ACRA data...\n",
      "Dataset Shape: (951620, 15)\n",
      "Starting enhanced classification with new categories...\n",
      "Total dataset: 951,620 records in 96 batches of 10,000 records each...\n",
      "Found existing file: acra_classified_full_dataset.csv\n",
      "Records already processed: 370,000\n",
      "Complete batches: 37\n",
      "✅ All batches up to batch 37 are complete\n",
      "\n",
      "🔄 RESUMING FROM INTERRUPTION\n",
      "Last completed batch: 37\n",
      "📁 Next 30 batches will be saved to: acra_classified_part2.csv\n",
      "📁 Final 29 batches will be saved to: acra_classified_part3.csv\n",
      "\n",
      "🚀 Starting batch processing from batch 38...\n",
      "\n",
      "--- Processing Batch 38/96 ---\n",
      "Records 370,000 to 379,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 38/96: 100%|██████████| 10000/10000 [04:22<00:00, 38.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new file: acra_classified_part2.csv\n",
      "Batch 38 'Others' percentage: 0.2%\n",
      "\n",
      "--- Processing Batch 39/96 ---\n",
      "Records 380,000 to 389,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 39/96: 100%|██████████| 10000/10000 [14:27<00:00, 11.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 39 to acra_classified_part2.csv\n",
      "Batch 39 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 40/96 ---\n",
      "Records 390,000 to 399,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 40/96: 100%|██████████| 10000/10000 [22:50<00:00,  7.29it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 40 to acra_classified_part2.csv\n",
      "Batch 40 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 41/96 ---\n",
      "Records 400,000 to 409,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 41/96: 100%|██████████| 10000/10000 [07:54<00:00, 21.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 41 to acra_classified_part2.csv\n",
      "Batch 41 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 42/96 ---\n",
      "Records 410,000 to 419,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 42/96: 100%|██████████| 10000/10000 [04:25<00:00, 37.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 42 to acra_classified_part2.csv\n",
      "Batch 42 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 43/96 ---\n",
      "Records 420,000 to 429,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 43/96: 100%|██████████| 10000/10000 [04:23<00:00, 37.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 43 to acra_classified_part2.csv\n",
      "Batch 43 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 44/96 ---\n",
      "Records 430,000 to 439,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 44/96: 100%|██████████| 10000/10000 [04:26<00:00, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 44 to acra_classified_part2.csv\n",
      "Batch 44 'Others' percentage: 0.6%\n",
      "\n",
      "--- Processing Batch 45/96 ---\n",
      "Records 440,000 to 449,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 45/96: 100%|██████████| 10000/10000 [04:28<00:00, 37.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 45 to acra_classified_part2.csv\n",
      "Batch 45 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 46/96 ---\n",
      "Records 450,000 to 459,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 46/96: 100%|██████████| 10000/10000 [04:30<00:00, 36.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 46 to acra_classified_part2.csv\n",
      "Batch 46 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 47/96 ---\n",
      "Records 460,000 to 469,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 47/96: 100%|██████████| 10000/10000 [04:34<00:00, 36.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 47 to acra_classified_part2.csv\n",
      "Batch 47 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 48/96 ---\n",
      "Records 470,000 to 479,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 48/96: 100%|██████████| 10000/10000 [04:29<00:00, 37.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 48 to acra_classified_part2.csv\n",
      "Batch 48 'Others' percentage: 0.5%\n",
      "\n",
      "--- Processing Batch 49/96 ---\n",
      "Records 480,000 to 489,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 49/96: 100%|██████████| 10000/10000 [04:34<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 49 to acra_classified_part2.csv\n",
      "Batch 49 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 50/96 ---\n",
      "Records 490,000 to 499,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 50/96: 100%|██████████| 10000/10000 [04:27<00:00, 37.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 50 to acra_classified_part2.csv\n",
      "Batch 50 'Others' percentage: 0.2%\n",
      "\n",
      "--- Processing Batch 51/96 ---\n",
      "Records 500,000 to 509,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 51/96: 100%|██████████| 10000/10000 [04:41<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 51 to acra_classified_part2.csv\n",
      "Batch 51 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 52/96 ---\n",
      "Records 510,000 to 519,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 52/96: 100%|██████████| 10000/10000 [04:33<00:00, 36.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 52 to acra_classified_part2.csv\n",
      "Batch 52 'Others' percentage: 0.6%\n",
      "\n",
      "--- Processing Batch 53/96 ---\n",
      "Records 520,000 to 529,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 53/96: 100%|██████████| 10000/10000 [04:52<00:00, 34.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 53 to acra_classified_part2.csv\n",
      "Batch 53 'Others' percentage: 0.5%\n",
      "\n",
      "--- Processing Batch 54/96 ---\n",
      "Records 530,000 to 539,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 54/96: 100%|██████████| 10000/10000 [04:47<00:00, 34.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 54 to acra_classified_part2.csv\n",
      "Batch 54 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 55/96 ---\n",
      "Records 540,000 to 549,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 55/96: 100%|██████████| 10000/10000 [04:39<00:00, 35.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 55 to acra_classified_part2.csv\n",
      "Batch 55 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 56/96 ---\n",
      "Records 550,000 to 559,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 56/96: 100%|██████████| 10000/10000 [04:41<00:00, 35.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 56 to acra_classified_part2.csv\n",
      "Batch 56 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 57/96 ---\n",
      "Records 560,000 to 569,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 57/96: 100%|██████████| 10000/10000 [04:21<00:00, 38.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 57 to acra_classified_part2.csv\n",
      "Batch 57 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 58/96 ---\n",
      "Records 570,000 to 579,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 58/96: 100%|██████████| 10000/10000 [04:23<00:00, 37.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 58 to acra_classified_part2.csv\n",
      "Batch 58 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 59/96 ---\n",
      "Records 580,000 to 589,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 59/96: 100%|██████████| 10000/10000 [04:19<00:00, 38.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 59 to acra_classified_part2.csv\n",
      "Batch 59 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 60/96 ---\n",
      "Records 590,000 to 599,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 60/96: 100%|██████████| 10000/10000 [04:19<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 60 to acra_classified_part2.csv\n",
      "Batch 60 'Others' percentage: 0.6%\n",
      "\n",
      "--- Processing Batch 61/96 ---\n",
      "Records 600,000 to 609,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 61/96: 100%|██████████| 10000/10000 [04:23<00:00, 37.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 61 to acra_classified_part2.csv\n",
      "Batch 61 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 62/96 ---\n",
      "Records 610,000 to 619,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 62/96: 100%|██████████| 10000/10000 [04:20<00:00, 38.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 62 to acra_classified_part2.csv\n",
      "Batch 62 'Others' percentage: 0.5%\n",
      "\n",
      "--- Processing Batch 63/96 ---\n",
      "Records 620,000 to 629,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 63/96: 100%|██████████| 10000/10000 [04:27<00:00, 37.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 63 to acra_classified_part2.csv\n",
      "Batch 63 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 64/96 ---\n",
      "Records 630,000 to 639,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 64/96: 100%|██████████| 10000/10000 [04:18<00:00, 38.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 64 to acra_classified_part2.csv\n",
      "Batch 64 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 65/96 ---\n",
      "Records 640,000 to 649,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 65/96: 100%|██████████| 10000/10000 [04:21<00:00, 38.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 65 to acra_classified_part2.csv\n",
      "Batch 65 'Others' percentage: 0.2%\n",
      "\n",
      "--- Processing Batch 66/96 ---\n",
      "Records 650,000 to 659,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 66/96: 100%|██████████| 10000/10000 [04:29<00:00, 37.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 66 to acra_classified_part2.csv\n",
      "Batch 66 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 67/96 ---\n",
      "Records 660,000 to 669,999\n",
      "Output file: acra_classified_part2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 67/96: 100%|██████████| 10000/10000 [04:35<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 67 to acra_classified_part2.csv\n",
      "Batch 67 'Others' percentage: 0.4%\n",
      "\n",
      "📁 Switching to new output file: acra_classified_part3.csv\n",
      "\n",
      "--- Processing Batch 68/96 ---\n",
      "Records 670,000 to 679,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 68/96: 100%|██████████| 10000/10000 [04:34<00:00, 36.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new file: acra_classified_part3.csv\n",
      "Batch 68 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 69/96 ---\n",
      "Records 680,000 to 689,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 69/96: 100%|██████████| 10000/10000 [04:18<00:00, 38.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 69 to acra_classified_part3.csv\n",
      "Batch 69 'Others' percentage: 0.2%\n",
      "\n",
      "--- Processing Batch 70/96 ---\n",
      "Records 690,000 to 699,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 70/96: 100%|██████████| 10000/10000 [04:19<00:00, 38.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 70 to acra_classified_part3.csv\n",
      "Batch 70 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 71/96 ---\n",
      "Records 700,000 to 709,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 71/96: 100%|██████████| 10000/10000 [04:18<00:00, 38.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 71 to acra_classified_part3.csv\n",
      "Batch 71 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 72/96 ---\n",
      "Records 710,000 to 719,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 72/96: 100%|██████████| 10000/10000 [04:18<00:00, 38.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 72 to acra_classified_part3.csv\n",
      "Batch 72 'Others' percentage: 0.5%\n",
      "\n",
      "--- Processing Batch 73/96 ---\n",
      "Records 720,000 to 729,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 73/96: 100%|██████████| 10000/10000 [04:27<00:00, 37.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 73 to acra_classified_part3.csv\n",
      "Batch 73 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 74/96 ---\n",
      "Records 730,000 to 739,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 74/96: 100%|██████████| 10000/10000 [04:20<00:00, 38.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 74 to acra_classified_part3.csv\n",
      "Batch 74 'Others' percentage: 0.5%\n",
      "\n",
      "--- Processing Batch 75/96 ---\n",
      "Records 740,000 to 749,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 75/96: 100%|██████████| 10000/10000 [04:19<00:00, 38.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 75 to acra_classified_part3.csv\n",
      "Batch 75 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 76/96 ---\n",
      "Records 750,000 to 759,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 76/96: 100%|██████████| 10000/10000 [04:19<00:00, 38.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 76 to acra_classified_part3.csv\n",
      "Batch 76 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 77/96 ---\n",
      "Records 760,000 to 769,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 77/96: 100%|██████████| 10000/10000 [04:30<00:00, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 77 to acra_classified_part3.csv\n",
      "Batch 77 'Others' percentage: 0.7%\n",
      "\n",
      "--- Processing Batch 78/96 ---\n",
      "Records 770,000 to 779,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 78/96: 100%|██████████| 10000/10000 [04:33<00:00, 36.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 78 to acra_classified_part3.csv\n",
      "Batch 78 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 79/96 ---\n",
      "Records 780,000 to 789,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 79/96: 100%|██████████| 10000/10000 [04:29<00:00, 37.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 79 to acra_classified_part3.csv\n",
      "Batch 79 'Others' percentage: 0.2%\n",
      "\n",
      "--- Processing Batch 80/96 ---\n",
      "Records 790,000 to 799,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 80/96: 100%|██████████| 10000/10000 [04:30<00:00, 36.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 80 to acra_classified_part3.csv\n",
      "Batch 80 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 81/96 ---\n",
      "Records 800,000 to 809,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 81/96: 100%|██████████| 10000/10000 [04:38<00:00, 35.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 81 to acra_classified_part3.csv\n",
      "Batch 81 'Others' percentage: 0.6%\n",
      "\n",
      "--- Processing Batch 82/96 ---\n",
      "Records 810,000 to 819,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 82/96: 100%|██████████| 10000/10000 [04:38<00:00, 35.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 82 to acra_classified_part3.csv\n",
      "Batch 82 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 83/96 ---\n",
      "Records 820,000 to 829,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 83/96: 100%|██████████| 10000/10000 [04:39<00:00, 35.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 83 to acra_classified_part3.csv\n",
      "Batch 83 'Others' percentage: 0.2%\n",
      "\n",
      "--- Processing Batch 84/96 ---\n",
      "Records 830,000 to 839,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 84/96: 100%|██████████| 10000/10000 [04:40<00:00, 35.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 84 to acra_classified_part3.csv\n",
      "Batch 84 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 85/96 ---\n",
      "Records 840,000 to 849,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 85/96: 100%|██████████| 10000/10000 [04:40<00:00, 35.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 85 to acra_classified_part3.csv\n",
      "Batch 85 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 86/96 ---\n",
      "Records 850,000 to 859,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 86/96: 100%|██████████| 10000/10000 [04:45<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 86 to acra_classified_part3.csv\n",
      "Batch 86 'Others' percentage: 0.2%\n",
      "\n",
      "--- Processing Batch 87/96 ---\n",
      "Records 860,000 to 869,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 87/96: 100%|██████████| 10000/10000 [04:29<00:00, 37.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 87 to acra_classified_part3.csv\n",
      "Batch 87 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 88/96 ---\n",
      "Records 870,000 to 879,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 88/96: 100%|██████████| 10000/10000 [04:27<00:00, 37.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 88 to acra_classified_part3.csv\n",
      "Batch 88 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 89/96 ---\n",
      "Records 880,000 to 889,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 89/96: 100%|██████████| 10000/10000 [04:21<00:00, 38.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 89 to acra_classified_part3.csv\n",
      "Batch 89 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 90/96 ---\n",
      "Records 890,000 to 899,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 90/96: 100%|██████████| 10000/10000 [04:21<00:00, 38.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 90 to acra_classified_part3.csv\n",
      "Batch 90 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 91/96 ---\n",
      "Records 900,000 to 909,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 91/96: 100%|██████████| 10000/10000 [04:19<00:00, 38.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 91 to acra_classified_part3.csv\n",
      "Batch 91 'Others' percentage: 0.5%\n",
      "\n",
      "--- Processing Batch 92/96 ---\n",
      "Records 910,000 to 919,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 92/96: 100%|██████████| 10000/10000 [04:20<00:00, 38.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 92 to acra_classified_part3.csv\n",
      "Batch 92 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 93/96 ---\n",
      "Records 920,000 to 929,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 93/96: 100%|██████████| 10000/10000 [04:21<00:00, 38.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 93 to acra_classified_part3.csv\n",
      "Batch 93 'Others' percentage: 0.2%\n",
      "\n",
      "--- Processing Batch 94/96 ---\n",
      "Records 930,000 to 939,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 94/96: 100%|██████████| 10000/10000 [04:20<00:00, 38.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 94 to acra_classified_part3.csv\n",
      "Batch 94 'Others' percentage: 0.3%\n",
      "\n",
      "--- Processing Batch 95/96 ---\n",
      "Records 940,000 to 949,999\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 95/96: 100%|██████████| 10000/10000 [04:20<00:00, 38.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 95 to acra_classified_part3.csv\n",
      "Batch 95 'Others' percentage: 0.4%\n",
      "\n",
      "--- Processing Batch 96/96 ---\n",
      "Records 950,000 to 951,619\n",
      "Output file: acra_classified_part3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 96/96: 100%|██████████| 1620/1620 [00:42<00:00, 37.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended batch 96 to acra_classified_part3.csv\n",
      "Batch 96 'Others' percentage: 0.4%\n",
      "\n",
      "🎉 BATCH PROCESSING COMPLETE!\n",
      "\n",
      "📊 OUTPUT FILES SUMMARY:\n",
      "📁 acra_classified_part2.csv: 300,000 records (30 batches)\n",
      "📁 acra_classified_part3.csv: 281,620 records (29 batches)\n",
      "\n",
      "📈 COMBINING RESULTS FROM ALL FILES...\n",
      "✅ Loaded 300,000 records from acra_classified_part2.csv\n",
      "✅ Loaded 281,620 records from acra_classified_part3.csv\n",
      "\n",
      "🔢 Combined dataset: 581,620 total records\n",
      "💾 Combined results saved to: acra_classified_combined_results.csv\n",
      "\n",
      "============================================================\n",
      "FINAL CLASSIFICATION RESULTS - COMBINED DATASET\n",
      "============================================================\n",
      "\n",
      "Category Distribution:\n",
      "Retail_services          : 416,378 ( 71.6%)\n",
      "Government_services      : 72,945 ( 12.5%)\n",
      "Essential_services       : 48,010 (  8.3%)\n",
      "Transport_services       : 29,681 (  5.1%)\n",
      "Education_institutions   : 26,931 (  4.6%)\n",
      "Healthcare_facilities    : 15,712 (  2.7%)\n",
      "Community_spaces         : 8,289 (  1.4%)\n",
      "Tourism                  : 5,680 (  1.0%)\n",
      "Residential              : 4,381 (  0.8%)\n",
      "Others                   : 2,204 (  0.4%)\n",
      "Emergency_services       : 2,101 (  0.4%)\n",
      "\n",
      "🎯 'Others' percentage: 0.4%\n",
      "\n",
      "Confidence Distribution:\n",
      "High confidence (≥0.7): 8,463 (1.5%)\n",
      "Medium confidence (0.4-0.7): 60,362 (10.4%)\n",
      "Low confidence (<0.4): 512,795 (88.2%)\n",
      "\n",
      "Sample Results (first 15 records):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Business: WHOLESALE OF LIQUOR, SOFT DRINKS AND BEVERAGES       → Retail_services           (0.20) [beverage, wholesale]\n",
      "Business: GENERAL CONTRACTORS (BUILDING CONSTRUCTION INCLUDI... → Retail_services           (0.20) [construction, building]\n",
      "Business: CHARTERED BUS SERVICES (INCLUDING SCHOOL BUSES)      → Education_institutions    (0.20) [school, art]\n",
      "Business: OTHER HOLDING COMPANIES                              → Government_services       (0.10) [pa]\n",
      "Business: SHIPPING COMPANIES, INCLUDING CHARTERING OF SHIPS ... → Transport_services        (0.30) [boat, shipping, freight]\n",
      "Business: EMPLOYMENT AGENCIES (EXCLUDING DOMESTIC WORKER EMP... → Essential_services        (0.10) [market]\n",
      "Business: WHOLESALE OF ELECTRONIC COMPONENTS                   → Retail_services           (0.10) [wholesale]\n",
      "Business: WHOLESALE OF METALS AND METAL ORES (EG STEEL PIPES... → Retail_services           (0.20) [hardware, wholesale]\n",
      "Business: LANDSCAPE DESIGN AND LANDSCAPE ARCHITECTURE          → Retail_services           (0.30) [design, architecture, it]\n",
      "Business: BUILDING CONSTRUCTION N.E.C.                         → Retail_services           (0.20) [construction, building]\n",
      "Business: MANAGEMENT CONSULTANCY SERVICES                      → Retail_services           (0.10) [services]\n",
      "Business: GENERAL CONTRACTORS (BUILDING CONSTRUCTION INCLUDI... → Retail_services           (0.20) [construction, building]\n",
      "Business: OTHER HOLDING COMPANIES                              → Government_services       (0.10) [pa]\n",
      "Business: OPERATORS AND CHARTERERS OF BARGES, TUGBOATS AND B... → Transport_services        (0.20) [boat, freight]\n",
      "Business: GENERAL CONTRACTORS (BUILDING CONSTRUCTION INCLUDI... → Retail_services           (0.20) [construction, building]\n",
      "\n",
      "✅ SUCCESS! Classification completed!\n",
      "📊 Total processed: 581,620 records\n",
      "\n",
      "🔮 FINAL RESULTS SUMMARY:\n",
      "Total records processed: 581,620\n",
      "'Others' category: 0.4% (2,204 records)\n",
      "Successfully classified: 99.6%\n",
      "\n",
      "📁 OUTPUT FILES:\n",
      "   acra_classified_part2.csv: 300,000 records\n",
      "   acra_classified_part3.csv: 281,620 records\n",
      "   acra_classified_combined_results.csv: 581,620 records (combined)\n",
      "\n",
      "🏁 PROCESSING COMPLETE!\n",
      "Check the output files for your classified data.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# ACRA Amenity Classification with MediaPipe Text Classifier\n",
    "# Updated Categories: Emergency, Healthcare, Essential, Residential, Education, \n",
    "# Transport, Tourism, Community, Government, Retail, Others\n",
    "# ENHANCED with Resume Capability and Expanded Keywords\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import text\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# ========================================================\n",
    "# PART 0: Resume Detection Function\n",
    "# ========================================================\n",
    "\n",
    "def check_batch_completion(output_file, expected_batch_size=10000):\n",
    "    \"\"\"Check which batches have been completed and determine where to resume.\"\"\"\n",
    "    if not os.path.exists(output_file):\n",
    "        print(f\"Output file {output_file} not found. Starting from beginning.\")\n",
    "        return 0, 0, False\n",
    "    \n",
    "    try:\n",
    "        df_existing = pd.read_csv(output_file)\n",
    "        records_processed = len(df_existing)\n",
    "        completed_batches = records_processed // expected_batch_size\n",
    "        records_in_last_batch = records_processed % expected_batch_size\n",
    "        \n",
    "        print(f\"Found existing file: {output_file}\")\n",
    "        print(f\"Records already processed: {records_processed:,}\")\n",
    "        print(f\"Complete batches: {completed_batches}\")\n",
    "        \n",
    "        if records_in_last_batch > 0:\n",
    "            print(f\"Partial batch {completed_batches + 1} has {records_in_last_batch} records\")\n",
    "            print(f\"❌ Batch {completed_batches + 1} is INCOMPLETE - will restart from this batch\")\n",
    "            return completed_batches, records_processed - records_in_last_batch, True\n",
    "        else:\n",
    "            print(f\"✅ All batches up to batch {completed_batches} are complete\")\n",
    "            return completed_batches, records_processed, True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading existing file: {e}\")\n",
    "        return 0, 0, False\n",
    "\n",
    "# ========================================================\n",
    "# PART 1: Setup MediaPipe Text Classifier\n",
    "# ========================================================\n",
    "\n",
    "print(\"Setting up MediaPipe Text Classifier...\")\n",
    "\n",
    "# Download the pre-trained model (this is free and runs locally)\n",
    "model_url = \"https://storage.googleapis.com/mediapipe-models/text_classifier/bert_classifier/float32/1/bert_classifier.tflite\"\n",
    "model_path = \"bert_classifier.tflite\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Downloading MediaPipe text classification model...\")\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "    print(\"Model downloaded successfully!\")\n",
    "\n",
    "# Create the text classifier\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = text.TextClassifierOptions(base_options=base_options)\n",
    "classifier = text.TextClassifier.create_from_options(options)\n",
    "\n",
    "# ========================================================\n",
    "# PART 2: Load Dataset\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading ACRA data...\")\n",
    "df = pd.read_csv(\"acra_merged_active.csv\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "if \"primary_ssic_description\" in df.columns:\n",
    "    col_name = \"primary_ssic_description\"\n",
    "elif \"primary_ssic\" in df.columns:\n",
    "    col_name = \"primary_ssic\"\n",
    "else:\n",
    "    raise ValueError(\"No SSIC description column found in CSV\")\n",
    "\n",
    "# Drop rows with empty descriptions\n",
    "df = df.dropna(subset=[col_name])\n",
    "df[col_name] = df[col_name].astype(str).str.strip()\n",
    "\n",
    "# ========================================================\n",
    "# PART 3: EXPANDED Classification Logic with New Categories\n",
    "# ========================================================\n",
    "\n",
    "# Define comprehensive keyword mappings for Singapore context - MASSIVELY EXPANDED\n",
    "category_keywords = {\n",
    "    \"Emergency_services\": [\n",
    "        \"emergency\", \"ambulance\", \"fire\", \"police\", \"rescue\", \"paramedic\",\n",
    "        \"emergency medical\", \"fire station\", \"police station\", \"civil defence\",\n",
    "        \"scdf\", \"spf\", \"disaster\", \"crisis\", \"urgent care\", \"first aid\",\n",
    "        \"emergency response\", \"safety\", \"security services\", \"emergency care\",\n",
    "        \"security\", \"guard\", \"surveillance\", \"protection\", \"patrol\", \"investigation\"\n",
    "    ],\n",
    "    \n",
    "    \"Healthcare_facilities\": [\n",
    "        \"hospital\", \"clinic\", \"medical\", \"health\", \"dental\", \"doctor\", \"physician\",\n",
    "        \"specialist\", \"diagnostic\", \"laboratory\", \"physiotherapy\", \"tcm\",\n",
    "        \"traditional chinese medicine\", \"veterinary\", \"vet\", \"mental health\",\n",
    "        \"rehabilitation\", \"nursing\", \"healthcare\", \"medicine\", \"pharmaceutical\",\n",
    "        \"wellness\", \"therapy\", \"treatment\", \"surgery\", \"radiology\", \"dentist\",\n",
    "        \"medical center\", \"health screening\", \"pharmacy\", \"medical practice\",\n",
    "        \"acupuncture\", \"chiropractic\", \"optometry\", \"podiatry\", \"psychology\",\n",
    "        \"counseling\", \"counselling\", \"pathology\", \"dermatology\", \"cardiology\",\n",
    "        \"oncology\", \"pediatric\", \"geriatric\", \"therapeutic\", \"clinical\", \"dialysis\"\n",
    "    ],\n",
    "    \n",
    "    \"Essential_services\": [\n",
    "        \"bank\", \"atm\", \"post office\", \"utility\", \"electricity\", \"water\", \"gas\",\n",
    "        \"postal\", \"singpost\", \"supermarket\", \"grocery\", \"market\", \"provision\",\n",
    "        \"convenience store\", \"pharmacy\", \"petrol\", \"fuel\", \"gas station\",\n",
    "        \"essential\", \"basic services\", \"public utilities\", \"waste management\",\n",
    "        \"recycling\", \"laundry\", \"dry cleaning\", \"repair services\", \"maintenance\",\n",
    "        \"cleaning\", \"pest control\", \"plumbing\", \"electrical\", \"aircon\",\n",
    "        \"air conditioning\", \"hvac\", \"installation\", \"servicing\", \"telecom\",\n",
    "        \"telecommunications\", \"internet\", \"broadband\", \"cable\", \"satellite\",\n",
    "        \"mini mart\", \"7-eleven\", \"cheers\", \"fairprice\", \"cold storage\", \"sheng siong\"\n",
    "    ],\n",
    "    \n",
    "    \"Residential\": [\n",
    "        \"residential\", \"housing\", \"apartment\", \"condominium\", \"condo\", \"hdb\",\n",
    "        \"flat\", \"estate\", \"home\", \"house\", \"residence\", \"dwelling\", \"villa\",\n",
    "        \"bungalow\", \"townhouse\", \"maisonette\", \"penthouse\", \"serviced apartment\",\n",
    "        \"dormitory\", \"hostel\", \"boarding\", \"lodging\", \"quarters\", \"living\",\n",
    "        \"property management\", \"estate management\", \"facilities management\", \"tenant\"\n",
    "    ],\n",
    "    \n",
    "    \"Education_institutions\": [\n",
    "        \"school\", \"education\", \"kindergarten\", \"preschool\", \"primary\", \"secondary\",\n",
    "        \"university\", \"college\", \"polytechnic\", \"institute\", \"tuition\", \"enrichment\",\n",
    "        \"training\", \"learning\", \"academic\", \"student\", \"teacher\", \"instructor\",\n",
    "        \"course\", \"class\", \"lesson\", \"workshop\", \"seminar\", \"coaching\",\n",
    "        \"educational\", \"study\", \"tutorial\", \"academy\", \"nursery\", \"childcare\",\n",
    "        \"daycare\", \"student care\", \"after school\", \"language\", \"music\", \"art\",\n",
    "        \"dance\", \"martial arts\", \"swimming coaching\", \"examination\", \"skills training\"\n",
    "    ],\n",
    "    \n",
    "    \"Transport_services\": [\n",
    "        \"transport\", \"mrt\", \"lrt\", \"bus\", \"taxi\", \"grab\", \"station\", \"interchange\",\n",
    "        \"terminal\", \"airport\", \"changi\", \"port\", \"ferry\", \"boat\", \"marina\",\n",
    "        \"parking\", \"carpark\", \"car park\", \"garage\", \"vehicle\", \"automotive\",\n",
    "        \"workshop\", \"service center\", \"petrol station\", \"logistics\", \"courier\",\n",
    "        \"delivery\", \"shipping\", \"freight\", \"warehouse\", \"storage\", \"moving\",\n",
    "        \"relocation\", \"trucking\", \"cargo\", \"forwarding\", \"express\", \"postal delivery\"\n",
    "    ],\n",
    "    \n",
    "    \"Tourism\": [\n",
    "        \"hotel\", \"resort\", \"hostel\", \"accommodation\", \"tourist\", \"tourism\",\n",
    "        \"attraction\", \"museum\", \"gallery\", \"heritage\", \"cultural\", \"zoo\",\n",
    "        \"aquarium\", \"theme park\", \"entertainment\", \"casino\", \"cruise\",\n",
    "        \"tour\", \"travel\", \"vacation\", \"holiday\", \"sightseeing\", \"landmark\",\n",
    "        \"monument\", \"gardens\", \"park\", \"beach\", \"island\", \"sentosa\",\n",
    "        \"marina bay\", \"orchard\", \"chinatown\", \"little india\", \"adventure\",\n",
    "        \"recreation\", \"amusement\", \"leisure activities\", \"excursion\", \"safari\"\n",
    "    ],\n",
    "    \n",
    "    \"Community_spaces\": [\n",
    "        \"community\", \"center\", \"centre\", \"club\", \"association\", \"society\",\n",
    "        \"library\", \"sports\", \"gym\", \"fitness\", \"swimming\", \"pool\", \"court\",\n",
    "        \"field\", \"playground\", \"park\", \"garden\", \"recreational\", \"leisure\",\n",
    "        \"activity\", \"social\", \"gathering\", \"meeting\", \"event\", \"function\",\n",
    "        \"hall\", \"auditorium\", \"pavilion\", \"void deck\", \"common area\",\n",
    "        \"volunteer\", \"charity\", \"non-profit\", \"foundation\", \"welfare\", \"ngo\"\n",
    "    ],\n",
    "    \n",
    "    \"Government_services\": [\n",
    "        \"government\", \"ministry\", \"statutory board\", \"public\", \"civil service\",\n",
    "        \"town council\", \"hdb office\", \"cpf\", \"iras\", \"mom\", \"moe\", \"moh\",\n",
    "        \"court\", \"tribunal\", \"registry\", \"authority\", \"agency\", \"commission\",\n",
    "        \"municipal\", \"grassroots\", \"pa\", \"people's association\", \"cc\",\n",
    "        \"community center\", \"rc\", \"residents committee\", \"official\",\n",
    "        \"parliament\", \"embassy\", \"consulate\", \"immigration\", \"customs\", \"ica\"\n",
    "    ],\n",
    "    \n",
    "    \"Retail_services\": [\n",
    "        \"retail\", \"shop\", \"store\", \"mart\", \"department store\", \"shopping\",\n",
    "        \"mall\", \"plaza\", \"fashion\", \"clothing\", \"electronics\", \"jewelry\",\n",
    "        \"jewellery\", \"hardware\", \"bookstore\", \"optical\", \"sporting goods\",\n",
    "        \"furniture\", \"toys\", \"pet\", \"beauty\", \"cosmetic\", \"salon\", \"spa\",\n",
    "        \"restaurant\", \"cafe\", \"coffee\", \"bar\", \"pub\", \"food court\", \"dining\",\n",
    "        \"catering\", \"bakery\", \"food\", \"beverage\", \"hawker\", \"entertainment\",\n",
    "        \"cinema\", \"ktv\", \"karaoke\", \"massage\", \"trading\", \"wholesale\",\n",
    "        \"import\", \"export\", \"distribution\", \"sales\", \"business\", \"commercial\",\n",
    "        \"manufacturing\", \"production\", \"processing\", \"packaging\", \"assembly\",\n",
    "        \"fabrication\", \"construction\", \"building\", \"renovation\", \"interior\",\n",
    "        \"design\", \"architecture\", \"engineering\", \"consulting\", \"advisory\",\n",
    "        \"professional services\", \"legal\", \"accounting\", \"finance\", \"insurance\",\n",
    "        \"real estate\", \"property\", \"investment\", \"marketing\", \"advertising\",\n",
    "        \"media\", \"publishing\", \"printing\", \"technology\", \"software\", \"it\",\n",
    "        \"computer\", \"digital\", \"online\", \"internet\", \"web\", \"app\", \"system\",\n",
    "        \"development\", \"programming\", \"data\", \"analytics\", \"research\", \"supply\",\n",
    "        \"services\", \"company\", \"enterprise\", \"corporation\", \"firm\", \"office\",\n",
    "        \"bureau\", \"agency\", \"solutions\", \"systems\", \"international\", \"global\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ========================================================\n",
    "# PART 4: Enhanced Classification Function (SAME APPROACH AS ORIGINAL)\n",
    "# ========================================================\n",
    "\n",
    "def classify_business_description(description: str, use_mediapipe: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Classify business description using hybrid approach:\n",
    "    1. MediaPipe for general sentiment/category hints\n",
    "    2. Keyword matching for specific Singapore business types\n",
    "    3. ENHANCED fallback logic to minimize 'Others' classification\n",
    "    \"\"\"\n",
    "    \n",
    "    description_lower = description.lower()\n",
    "    \n",
    "    # Method 1: Keyword-based classification (primary) - SAME AS ORIGINAL\n",
    "    category_scores = {}\n",
    "    \n",
    "    for category, keywords in category_keywords.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in description_lower:\n",
    "                # Weight longer, more specific keywords higher\n",
    "                weight = len(keyword.split()) * 2 if len(keyword.split()) > 1 else 1\n",
    "                score += weight\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if score > 0:\n",
    "            category_scores[category] = {\n",
    "                'score': score,\n",
    "                'keywords': matched_keywords,\n",
    "                'confidence': min(score / 10.0, 1.0)  # Normalize confidence\n",
    "            }\n",
    "    \n",
    "    # Method 2: Use MediaPipe for additional insights (SAME AS ORIGINAL)\n",
    "    mediapipe_result = None\n",
    "    if use_mediapipe:\n",
    "        try:\n",
    "            classification_result = classifier.classify(description)\n",
    "            if classification_result.classifications:\n",
    "                # Extract top classification\n",
    "                top_classification = classification_result.classifications[0]\n",
    "                if top_classification.categories:\n",
    "                    top_category = top_classification.categories[0]\n",
    "                    mediapipe_result = {\n",
    "                        'category': top_category.category_name,\n",
    "                        'score': top_category.score\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            print(f\"MediaPipe classification error: {e}\")\n",
    "    \n",
    "    # Method 3: ENHANCED fallback logic for common Singapore business patterns\n",
    "    if not category_scores:\n",
    "        # EXPANDED broader keyword matching\n",
    "        broad_keywords = {\n",
    "            'service': ['Essential_services', 'Retail_services'],\n",
    "            'services': ['Essential_services', 'Retail_services'],\n",
    "            'company': ['Retail_services', 'Essential_services'],\n",
    "            'center': ['Community_spaces', 'Healthcare_facilities'],\n",
    "            'centre': ['Community_spaces', 'Healthcare_facilities'],\n",
    "            'management': ['Retail_services', 'Essential_services'],\n",
    "            'trading': ['Retail_services'],\n",
    "            'engineering': ['Essential_services'],\n",
    "            'development': ['Retail_services'],\n",
    "            'construction': ['Essential_services'],\n",
    "            'technology': ['Retail_services'],\n",
    "            'consulting': ['Retail_services'],\n",
    "            'solutions': ['Retail_services'],\n",
    "            'systems': ['Retail_services'],\n",
    "            'international': ['Retail_services'],\n",
    "            'industrial': ['Essential_services'],\n",
    "            'manufacturing': ['Essential_services'],\n",
    "            # NEW ADDITIONS to reduce Others\n",
    "            'business': ['Retail_services'],\n",
    "            'enterprise': ['Retail_services'],\n",
    "            'corporation': ['Retail_services'],\n",
    "            'firm': ['Retail_services'],\n",
    "            'office': ['Retail_services'],\n",
    "            'agency': ['Retail_services'],\n",
    "            'bureau': ['Retail_services'],\n",
    "            'supply': ['Retail_services'],\n",
    "            'distribution': ['Retail_services'],\n",
    "            'wholesale': ['Retail_services'],\n",
    "            'retail': ['Retail_services'],\n",
    "            'sales': ['Retail_services'],\n",
    "            'marketing': ['Retail_services'],\n",
    "            'design': ['Retail_services'],\n",
    "            'consulting': ['Retail_services'],\n",
    "            'advisory': ['Retail_services'],\n",
    "            'professional': ['Retail_services'],\n",
    "            'legal': ['Retail_services'],\n",
    "            'financial': ['Retail_services'],\n",
    "            'investment': ['Retail_services'],\n",
    "            'insurance': ['Retail_services'],\n",
    "            'property': ['Retail_services'],\n",
    "            'maintenance': ['Essential_services'],\n",
    "            'repair': ['Essential_services'],\n",
    "            'installation': ['Essential_services'],\n",
    "            'cleaning': ['Essential_services'],\n",
    "            'waste': ['Essential_services'],\n",
    "            'utility': ['Essential_services'],\n",
    "            'transport': ['Transport_services'],\n",
    "            'logistics': ['Transport_services'],\n",
    "            'delivery': ['Transport_services'],\n",
    "            'shipping': ['Transport_services'],\n",
    "            'freight': ['Transport_services'],\n",
    "            'storage': ['Transport_services'],\n",
    "            'warehouse': ['Transport_services']\n",
    "        }\n",
    "        \n",
    "        for keyword, potential_categories in broad_keywords.items():\n",
    "            if keyword in description_lower:\n",
    "                # Assign to most likely category with lower confidence\n",
    "                category_scores[potential_categories[0]] = {\n",
    "                    'score': 1,\n",
    "                    'keywords': [keyword],\n",
    "                    'confidence': 0.4\n",
    "                }\n",
    "                break\n",
    "        \n",
    "        # FINAL FALLBACK: If still no match, try even more general patterns\n",
    "        if not category_scores:\n",
    "            # Look for common business structure words\n",
    "            business_indicators = ['pte', 'ltd', 'llp', 'limited', 'private', 'public', 'holdings', 'group']\n",
    "            if any(indicator in description_lower for indicator in business_indicators):\n",
    "                category_scores['Retail_services'] = {\n",
    "                    'score': 1,\n",
    "                    'keywords': ['business_entity'],\n",
    "                    'confidence': 0.3\n",
    "                }\n",
    "            # Look for action words that suggest commercial activity\n",
    "            elif any(word in description_lower for word in ['sale', 'selling', 'purchase', 'buy', 'sell', 'trade', 'deal']):\n",
    "                category_scores['Retail_services'] = {\n",
    "                    'score': 1,\n",
    "                    'keywords': ['commercial_activity'],\n",
    "                    'confidence': 0.3\n",
    "                }\n",
    "            # Default for multi-word descriptions (likely business)\n",
    "            elif len(description_lower.split()) >= 3:\n",
    "                category_scores['Retail_services'] = {\n",
    "                    'score': 1,\n",
    "                    'keywords': ['default_business'],\n",
    "                    'confidence': 0.2\n",
    "                }\n",
    "    \n",
    "    # Final decision logic (SAME AS ORIGINAL)\n",
    "    if category_scores:\n",
    "        # Get category with highest score\n",
    "        best_category = max(category_scores.items(), key=lambda x: x[1]['score'])\n",
    "        \n",
    "        primary_category = best_category[0]\n",
    "        confidence = best_category[1]['confidence']\n",
    "        keywords_matched = best_category[1]['keywords']\n",
    "        \n",
    "        # Get secondary categories if they exist\n",
    "        secondary_categories = [cat for cat, data in category_scores.items() \n",
    "                             if cat != primary_category and data['score'] >= 2]\n",
    "        \n",
    "        all_categories = [primary_category] + secondary_categories[:2]  # Max 3 categories\n",
    "        \n",
    "        return all_categories, confidence, keywords_matched\n",
    "    \n",
    "    else:\n",
    "        # Last resort: default to Others (should be much less now)\n",
    "        return ['Others'], 0.2, ['no_keywords_matched']\n",
    "\n",
    "# ========================================================\n",
    "# PART 5: Apply Classification with Resume Capability\n",
    "# ========================================================\n",
    "\n",
    "print(\"Starting enhanced classification with new categories...\")\n",
    "\n",
    "# Batch processing configuration\n",
    "BATCH_SIZE = 10000\n",
    "total_records = len(df)\n",
    "num_batches = (total_records + BATCH_SIZE - 1) // BATCH_SIZE  # Ceiling division\n",
    "main_output_path = \"acra_classified_full_dataset.csv\"\n",
    "\n",
    "print(f\"Total dataset: {total_records:,} records in {num_batches} batches of {BATCH_SIZE:,} records each...\")\n",
    "\n",
    "# Check completion status\n",
    "last_completed_batch, records_processed, should_resume = check_batch_completion(main_output_path, BATCH_SIZE)\n",
    "\n",
    "if should_resume and last_completed_batch >= 31:  # Batch 32 or later\n",
    "    print(f\"\\n🔄 RESUMING FROM INTERRUPTION\")\n",
    "    print(f\"Last completed batch: {last_completed_batch}\")\n",
    "    \n",
    "    # Determine output files for remaining batches\n",
    "    remaining_batches = num_batches - last_completed_batch\n",
    "    \n",
    "    if remaining_batches <= 30:\n",
    "        # All remaining batches go to one file\n",
    "        output_files = [(\"acra_classified_part2.csv\", remaining_batches)]\n",
    "        print(f\"📁 Remaining {remaining_batches} batches will be saved to: acra_classified_part2.csv\")\n",
    "    else:\n",
    "        # Split remaining batches into two files\n",
    "        first_part_batches = 30\n",
    "        second_part_batches = remaining_batches - 30\n",
    "        output_files = [\n",
    "            (\"acra_classified_part2.csv\", first_part_batches),\n",
    "            (\"acra_classified_part3.csv\", second_part_batches)\n",
    "        ]\n",
    "        print(f\"📁 Next 30 batches will be saved to: acra_classified_part2.csv\")\n",
    "        print(f\"📁 Final {second_part_batches} batches will be saved to: acra_classified_part3.csv\")\n",
    "    \n",
    "    start_batch = last_completed_batch\n",
    "    \n",
    "else:\n",
    "    # Start from beginning or continue normal processing\n",
    "    if should_resume:\n",
    "        print(f\"✅ Continuing from batch {last_completed_batch + 1}\")\n",
    "        start_batch = last_completed_batch\n",
    "    else:\n",
    "        print(\"🆕 Starting fresh processing\")\n",
    "        start_batch = 0\n",
    "    \n",
    "    # For normal processing, use original file\n",
    "    output_files = [(main_output_path, num_batches)]\n",
    "\n",
    "# Process in batches with multiple output files\n",
    "current_file_index = 0\n",
    "batches_in_current_file = 0\n",
    "current_output_path = output_files[current_file_index][0]\n",
    "max_batches_current_file = output_files[current_file_index][1]\n",
    "\n",
    "print(f\"\\n🚀 Starting batch processing from batch {start_batch + 1}...\")\n",
    "\n",
    "for batch_num in range(start_batch, num_batches):\n",
    "    # Check if we need to switch to next output file\n",
    "    if batches_in_current_file >= max_batches_current_file and current_file_index < len(output_files) - 1:\n",
    "        current_file_index += 1\n",
    "        current_output_path = output_files[current_file_index][0]\n",
    "        max_batches_current_file = output_files[current_file_index][1]\n",
    "        batches_in_current_file = 0\n",
    "        print(f\"\\n📁 Switching to new output file: {current_output_path}\")\n",
    "    \n",
    "    start_idx = batch_num * BATCH_SIZE\n",
    "    end_idx = min((batch_num + 1) * BATCH_SIZE, total_records)\n",
    "    \n",
    "    print(f\"\\n--- Processing Batch {batch_num + 1}/{num_batches} ---\")\n",
    "    print(f\"Records {start_idx:,} to {end_idx-1:,}\")\n",
    "    print(f\"Output file: {current_output_path}\")\n",
    "    \n",
    "    # Get current batch\n",
    "    df_batch = df.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    # Process batch (SAME AS ORIGINAL)\n",
    "    results = []\n",
    "    for desc in tqdm(df_batch[col_name].astype(str).tolist(), \n",
    "                     desc=f\"Batch {batch_num + 1}/{num_batches}\"):\n",
    "        result = classify_business_description(desc)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Unpack results (SAME AS ORIGINAL)\n",
    "    categories_list, confidences, keywords_matched = zip(*results)\n",
    "    \n",
    "    df_batch['amenity_categories'] = [', '.join(cats) for cats in categories_list]\n",
    "    df_batch['classification_confidence'] = confidences\n",
    "    df_batch['keywords_matched'] = [', '.join(kw) for kw in keywords_matched]\n",
    "    \n",
    "    # Save batch results\n",
    "    if batches_in_current_file == 0:\n",
    "        # First batch in this file - create new file with headers\n",
    "        df_batch.to_csv(current_output_path, index=False, mode='w')\n",
    "        print(f\"Created new file: {current_output_path}\")\n",
    "    else:\n",
    "        # Subsequent batches - append without headers\n",
    "        df_batch.to_csv(current_output_path, index=False, mode='a', header=False)\n",
    "        print(f\"Appended batch {batch_num + 1} to {current_output_path}\")\n",
    "    \n",
    "    batches_in_current_file += 1\n",
    "    \n",
    "    # Quick batch analysis (SAME AS ORIGINAL)\n",
    "    batch_category_counts = (\n",
    "        df_batch['amenity_categories']\n",
    "        .str.split(', ')\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "    )\n",
    "    \n",
    "    batch_others_pct = (batch_category_counts.get('Others', 0) / len(df_batch)) * 100\n",
    "    print(f\"Batch {batch_num + 1} 'Others' percentage: {batch_others_pct:.1f}%\")\n",
    "    \n",
    "    # Memory cleanup (SAME AS ORIGINAL)\n",
    "    del df_batch, results, categories_list, confidences, keywords_matched\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\n🎉 BATCH PROCESSING COMPLETE!\")\n",
    "\n",
    "# Display summary of output files\n",
    "print(f\"\\n📊 OUTPUT FILES SUMMARY:\")\n",
    "for file_path, expected_batches in output_files:\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            df_check = pd.read_csv(file_path)\n",
    "            actual_records = len(df_check)\n",
    "            actual_batches = (actual_records + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "            print(f\"📁 {file_path}: {actual_records:,} records ({actual_batches} batches)\")\n",
    "        except Exception as e:\n",
    "            print(f\"📁 {file_path}: Error reading file - {e}\")\n",
    "    else:\n",
    "        print(f\"📁 {file_path}: File not created\")\n",
    "\n",
    "# ========================================================\n",
    "# PART 6: Final Analysis (Read back results from all files)\n",
    "# ========================================================\n",
    "\n",
    "print(f\"\\n📈 COMBINING RESULTS FROM ALL FILES...\")\n",
    "\n",
    "# Combine all output files for analysis\n",
    "all_dataframes = []\n",
    "total_processed = 0\n",
    "\n",
    "for file_path, _ in output_files:\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            df_part = pd.read_csv(file_path)\n",
    "            all_dataframes.append(df_part)\n",
    "            total_processed += len(df_part)\n",
    "            print(f\"✅ Loaded {len(df_part):,} records from {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {file_path}: {e}\")\n",
    "\n",
    "if all_dataframes:\n",
    "    # Combine all dataframes\n",
    "    df_final = pd.concat(all_dataframes, ignore_index=True)\n",
    "    print(f\"\\n🔢 Combined dataset: {len(df_final):,} total records\")\n",
    "    \n",
    "    # Save combined results\n",
    "    combined_output_path = \"acra_classified_combined_results.csv\"\n",
    "    df_final.to_csv(combined_output_path, index=False)\n",
    "    print(f\"💾 Combined results saved to: {combined_output_path}\")\n",
    "    \n",
    "    # ========================================================\n",
    "    # PART 7: Detailed Analysis (SAME AS ORIGINAL)\n",
    "    # ========================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION RESULTS - COMBINED DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Category distribution\n",
    "    category_counts = (\n",
    "        df_final['amenity_categories']\n",
    "        .str.split(', ')\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCategory Distribution:\")\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df_final)) * 100\n",
    "        print(f\"{category:25}: {count:,} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Key improvements\n",
    "    others_pct = (category_counts.get('Others', 0) / len(df_final)) * 100\n",
    "    print(f\"\\n🎯 'Others' percentage: {others_pct:.1f}%\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    high_conf = len(df_final[df_final['classification_confidence'] >= 0.7])\n",
    "    medium_conf = len(df_final[(df_final['classification_confidence'] >= 0.4) & \n",
    "                               (df_final['classification_confidence'] < 0.7)])\n",
    "    low_conf = len(df_final[df_final['classification_confidence'] < 0.4])\n",
    "    \n",
    "    print(f\"\\nConfidence Distribution:\")\n",
    "    print(f\"High confidence (≥0.7): {high_conf:,} ({high_conf/len(df_final)*100:.1f}%)\")\n",
    "    print(f\"Medium confidence (0.4-0.7): {medium_conf:,} ({medium_conf/len(df_final)*100:.1f}%)\")\n",
    "    print(f\"Low confidence (<0.4): {low_conf:,} ({low_conf/len(df_final)*100:.1f}%)\")\n",
    "    \n",
    "    # Sample results\n",
    "    print(f\"\\nSample Results (first 15 records):\")\n",
    "    print(\"-\" * 120)\n",
    "    for idx in range(min(15, len(df_final))):\n",
    "        row = df_final.iloc[idx]\n",
    "        desc = row[col_name][:50] + \"...\" if len(row[col_name]) > 50 else row[col_name]\n",
    "        print(f\"Business: {desc:52} → {row['amenity_categories']:25} \"\n",
    "              f\"({row['classification_confidence']:.2f}) [{row['keywords_matched'][:30]}]\")\n",
    "    \n",
    "    print(f\"\\n✅ SUCCESS! Classification completed!\")\n",
    "    print(f\"📊 Total processed: {len(df_final):,} records\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n🔮 FINAL RESULTS SUMMARY:\")\n",
    "    print(f\"Total records processed: {len(df_final):,}\")\n",
    "    print(f\"'Others' category: {others_pct:.1f}% ({category_counts.get('Others', 0):,} records)\")\n",
    "    print(f\"Successfully classified: {100 - others_pct:.1f}%\")\n",
    "    \n",
    "    # Show file breakdown\n",
    "    print(f\"\\n📁 OUTPUT FILES:\")\n",
    "    for file_path, _ in output_files:\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df_check = pd.read_csv(file_path)\n",
    "                print(f\"   {file_path}: {len(df_check):,} records\")\n",
    "            except:\n",
    "                print(f\"   {file_path}: Error reading\")\n",
    "    \n",
    "    print(f\"   {combined_output_path}: {len(df_final):,} records (combined)\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No data available for final analysis\")\n",
    "\n",
    "print(f\"\\n🏁 PROCESSING COMPLETE!\")\n",
    "print(f\"Check the output files for your classified data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2889c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MediaPipe Text Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757170567.708837   15117 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2\n",
      "W0000 00:00:1757170567.922912  335854 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ACRA data...\n",
      "Full Dataset Shape: (951620, 15)\n",
      "Sample Dataset Shape: (5000, 15)\n",
      "Final sample size after cleaning: 5,000 records\n",
      "Starting classification without Method 3 fallback logic...\n",
      "Processing 5,000 records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 5000/5000 [02:15<00:00, 37.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample results saved to: acra_sample_no_method3.csv\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION RESULTS - WITHOUT METHOD 3\n",
      "============================================================\n",
      "\n",
      "Category Distribution:\n",
      "Retail_services          : 2,919 ( 58.4%)\n",
      "Government_services      : 685 ( 13.7%)\n",
      "Others                   : 475 (  9.5%)\n",
      "Essential_services       : 398 (  8.0%)\n",
      "Transport_services       : 295 (  5.9%)\n",
      "Education_institutions   : 264 (  5.3%)\n",
      "Healthcare_facilities    : 150 (  3.0%)\n",
      "Community_spaces         : 72 (  1.4%)\n",
      "Tourism                  : 62 (  1.2%)\n",
      "Residential              : 41 (  0.8%)\n",
      "Emergency_services       : 24 (  0.5%)\n",
      "\n",
      "🎯 Key Metrics:\n",
      "Retail_services: 58.4%\n",
      "Others: 9.5%\n",
      "\n",
      "Confidence Distribution:\n",
      "High confidence (≥0.7): 60 (1.2%)\n",
      "Medium confidence (0.4-0.7): 433 (8.7%)\n",
      "Low confidence (<0.4): 4,507 (90.1%)\n",
      "\n",
      "📋 SAMPLE CLASSIFICATIONS BY CATEGORY:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Retail_services:\n",
      "  • RETAIL SALE OF HOUSEHOLD ELECTRICAL APPLIANCES AND EQUIPMENT... (conf: 0.20)\n",
      "  • DEPARTMENT STORES (conf: 0.50)\n",
      "  • ENGINEERING DESIGN AND CONSULTANCY ACTIVITIES N.E.C. (conf: 0.30)\n",
      "\n",
      "Government_services:\n",
      "  • OTHER HOLDING COMPANIES (conf: 0.10)\n",
      "  • MANUFACTURE AND REPAIR OF LIFTING AND HANDLING EQUIPMENT N.E... (conf: 0.10)\n",
      "  • HUMAN RESOURCE CONSULTANCY SERVICES (conf: 0.10)\n",
      "\n",
      "Others:\n",
      "  • LIGHTERAGE SERVICES (conf: 0.10)\n",
      "  • CAR WASHING AND RELATED SERVICES (conf: 0.10)\n",
      "  • ORNAMENTAL FISH FARMS (conf: 0.10)\n",
      "\n",
      "Essential_services:\n",
      "  • MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS (conf: 0.50)\n",
      "  • EMPLOYMENT AGENCIES (EXCLUDING DOMESTIC WORKER EMPLOYMENT PL... (conf: 0.10)\n",
      "  • MINI-MARTS, CONVENIENCE STORES AND PROVISION SHOPS (conf: 0.50)\n",
      "\n",
      "Transport_services:\n",
      "  • SHIPPING COMPANIES, INCLUDING CHARTERING OF SHIPS AND BOATS ... (conf: 0.30)\n",
      "  • TRAINING COURSES FOR WHOLESALE TRADE, LOGISTICS AND TRANSPOR... (conf: 0.30)\n",
      "  • FOOD KIOSKS MAINLY FOR TAKEAWAY AND DELIVERY (conf: 0.10)\n",
      "\n",
      "Education_institutions:\n",
      "  • NIGHT CLUBS, DISCOTHEQUES, DANCE CLUBS AND KARAOKE LOUNGES (conf: 0.10)\n",
      "  • TRAINING COURSES FOR MUSIC, DANCING, ART, SPEECH AND DRAMA (conf: 0.40)\n",
      "  • TRAINING COURSES FOR WHOLESALE TRADE, LOGISTICS AND TRANSPOR... (conf: 0.30)\n",
      "\n",
      "Healthcare_facilities:\n",
      "  • CLINICS AND OTHER GENERAL MEDICAL SERVICES (WESTERN) (conf: 0.20)\n",
      "  • WHOLESALE OF HEALTH SUPPLEMENTS (conf: 0.10)\n",
      "  • WHOLESALE OF HEALTH SUPPLEMENTS (conf: 0.10)\n",
      "\n",
      "Community_spaces:\n",
      "  • EVENT/CONCERT ORGANISERS (conf: 0.10)\n",
      "  • FITNESS CENTRES AND GYMNASIUMS (conf: 0.30)\n",
      "  • FITNESS CENTRES AND GYMNASIUMS (conf: 0.30)\n",
      "\n",
      "Tourism:\n",
      "  • HOTELS (conf: 0.10)\n",
      "  • HOTELS (conf: 0.10)\n",
      "  • RETAIL SALE OF BAGS, LUGGAGE AND TRAVEL ACCESSORIES (conf: 0.10)\n",
      "\n",
      "Residential:\n",
      "  • GENERAL WAREHOUSING (conf: 0.10)\n",
      "  • HOSTELS AND DORMITORIES FOR STUDENTS, WORKERS AND OTHER INDI... (conf: 0.10)\n",
      "  • WHOLESALE OF FURNITURE, HOME FURNISHINGS AND OTHER HOUSEHOLD... (conf: 0.30)\n",
      "\n",
      "❓ EXAMPLES OF 'Others' CATEGORY:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  • LIGHTERAGE SERVICES\n",
      "  • CAR WASHING AND RELATED SERVICES\n",
      "  • ORNAMENTAL FISH FARMS\n",
      "  • SELF-OPERATED LAUNDRIES\n",
      "  • LIGHTERAGE SERVICES\n",
      "  • GROWING OF OTHER CROPS\n",
      "  • MANAGEMENT CONSULTANCY SERVICES\n",
      "  • LAND RECLAMATION WORKS\n",
      "  • SHIP CHANDLERS\n",
      "  • MANAGEMENT CONSULTANCY SERVICES\n",
      "\n",
      "✅ ANALYSIS COMPLETE!\n",
      "📊 Total sample processed: 5,000 records\n",
      "📉 Retail_services reduced from ~70% to 58.4%\n",
      "📈 Others increased to 9.5%\n",
      "💾 Results saved to: acra_sample_no_method3.csv\n",
      "\n",
      "🔍 RECOMMENDATION:\n",
      "⚠️  Retail_services is still high. Consider refining the keywords further.\n",
      "✅ 'Others' percentage is reasonable.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# ACRA Amenity Classification with MediaPipe Text Classifier\n",
    "# UPDATED: Removed Method 3 fallback logic to reduce Retail_services bias\n",
    "# Testing on 5000 records sample\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import text\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# ========================================================\n",
    "# PART 1: Setup MediaPipe Text Classifier\n",
    "# ========================================================\n",
    "\n",
    "print(\"Setting up MediaPipe Text Classifier...\")\n",
    "\n",
    "# Download the pre-trained model (this is free and runs locally)\n",
    "model_url = \"https://storage.googleapis.com/mediapipe-models/text_classifier/bert_classifier/float32/1/bert_classifier.tflite\"\n",
    "model_path = \"bert_classifier.tflite\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Downloading MediaPipe text classification model...\")\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "    print(\"Model downloaded successfully!\")\n",
    "\n",
    "# Create the text classifier\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = text.TextClassifierOptions(base_options=base_options)\n",
    "classifier = text.TextClassifier.create_from_options(options)\n",
    "\n",
    "# ========================================================\n",
    "# PART 2: Load Dataset (Sample of 5000 records)\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading ACRA data...\")\n",
    "df_full = pd.read_csv(\"acra_merged_active.csv\")\n",
    "print(\"Full Dataset Shape:\", df_full.shape)\n",
    "\n",
    "# Take a sample of 5000 records for testing\n",
    "df = df_full.sample(n=5000, random_state=42).reset_index(drop=True)\n",
    "print(\"Sample Dataset Shape:\", df.shape)\n",
    "\n",
    "if \"primary_ssic_description\" in df.columns:\n",
    "    col_name = \"primary_ssic_description\"\n",
    "elif \"primary_ssic\" in df.columns:\n",
    "    col_name = \"primary_ssic\"\n",
    "else:\n",
    "    raise ValueError(\"No SSIC description column found in CSV\")\n",
    "\n",
    "# Drop rows with empty descriptions\n",
    "df = df.dropna(subset=[col_name])\n",
    "df[col_name] = df[col_name].astype(str).str.strip()\n",
    "\n",
    "print(f\"Final sample size after cleaning: {len(df):,} records\")\n",
    "\n",
    "# ========================================================\n",
    "# PART 3: Classification Logic with Keywords (Same as original)\n",
    "# ========================================================\n",
    "\n",
    "# Define comprehensive keyword mappings for Singapore context\n",
    "category_keywords = {\n",
    "    \"Emergency_services\": [\n",
    "        \"emergency\", \"ambulance\", \"fire\", \"police\", \"rescue\", \"paramedic\",\n",
    "        \"emergency medical\", \"fire station\", \"police station\", \"civil defence\",\n",
    "        \"scdf\", \"spf\", \"disaster\", \"crisis\", \"urgent care\", \"first aid\",\n",
    "        \"emergency response\", \"safety\", \"security services\", \"emergency care\",\n",
    "        \"security\", \"guard\", \"surveillance\", \"protection\", \"patrol\", \"investigation\"\n",
    "    ],\n",
    "    \n",
    "    \"Healthcare_facilities\": [\n",
    "        \"hospital\", \"clinic\", \"medical\", \"health\", \"dental\", \"doctor\", \"physician\",\n",
    "        \"specialist\", \"diagnostic\", \"laboratory\", \"physiotherapy\", \"tcm\",\n",
    "        \"traditional chinese medicine\", \"veterinary\", \"vet\", \"mental health\",\n",
    "        \"rehabilitation\", \"nursing\", \"healthcare\", \"medicine\", \"pharmaceutical\",\n",
    "        \"wellness\", \"therapy\", \"treatment\", \"surgery\", \"radiology\", \"dentist\",\n",
    "        \"medical center\", \"health screening\", \"pharmacy\", \"medical practice\",\n",
    "        \"acupuncture\", \"chiropractic\", \"optometry\", \"podiatry\", \"psychology\",\n",
    "        \"counseling\", \"counselling\", \"pathology\", \"dermatology\", \"cardiology\",\n",
    "        \"oncology\", \"pediatric\", \"geriatric\", \"therapeutic\", \"clinical\", \"dialysis\"\n",
    "    ],\n",
    "    \n",
    "    \"Essential_services\": [\n",
    "        \"bank\", \"atm\", \"post office\", \"utility\", \"electricity\", \"water\", \"gas\",\n",
    "        \"postal\", \"singpost\", \"supermarket\", \"grocery\", \"market\", \"provision\",\n",
    "        \"convenience store\", \"pharmacy\", \"petrol\", \"fuel\", \"gas station\",\n",
    "        \"essential\", \"basic services\", \"public utilities\", \"waste management\",\n",
    "        \"recycling\", \"laundry\", \"dry cleaning\", \"repair services\", \"maintenance\",\n",
    "        \"cleaning\", \"pest control\", \"plumbing\", \"electrical\", \"aircon\",\n",
    "        \"air conditioning\", \"hvac\", \"installation\", \"servicing\", \"telecom\",\n",
    "        \"telecommunications\", \"internet\", \"broadband\", \"cable\", \"satellite\",\n",
    "        \"mini mart\", \"7-eleven\", \"cheers\", \"fairprice\", \"cold storage\", \"sheng siong\"\n",
    "    ],\n",
    "    \n",
    "    \"Residential\": [\n",
    "        \"residential\", \"housing\", \"apartment\", \"condominium\", \"condo\", \"hdb\",\n",
    "        \"flat\", \"estate\", \"home\", \"house\", \"residence\", \"dwelling\", \"villa\",\n",
    "        \"bungalow\", \"townhouse\", \"maisonette\", \"penthouse\", \"serviced apartment\",\n",
    "        \"dormitory\", \"hostel\", \"boarding\", \"lodging\", \"quarters\", \"living\",\n",
    "        \"property management\", \"estate management\", \"facilities management\", \"tenant\"\n",
    "    ],\n",
    "    \n",
    "    \"Education_institutions\": [\n",
    "        \"school\", \"education\", \"kindergarten\", \"preschool\", \"primary\", \"secondary\",\n",
    "        \"university\", \"college\", \"polytechnic\", \"institute\", \"tuition\", \"enrichment\",\n",
    "        \"training\", \"learning\", \"academic\", \"student\", \"teacher\", \"instructor\",\n",
    "        \"course\", \"class\", \"lesson\", \"workshop\", \"seminar\", \"coaching\",\n",
    "        \"educational\", \"study\", \"tutorial\", \"academy\", \"nursery\", \"childcare\",\n",
    "        \"daycare\", \"student care\", \"after school\", \"language\", \"music\", \"art\",\n",
    "        \"dance\", \"martial arts\", \"swimming coaching\", \"examination\", \"skills training\"\n",
    "    ],\n",
    "    \n",
    "    \"Transport_services\": [\n",
    "        \"transport\", \"mrt\", \"lrt\", \"bus\", \"taxi\", \"grab\", \"station\", \"interchange\",\n",
    "        \"terminal\", \"airport\", \"changi\", \"port\", \"ferry\", \"boat\", \"marina\",\n",
    "        \"parking\", \"carpark\", \"car park\", \"garage\", \"vehicle\", \"automotive\",\n",
    "        \"workshop\", \"service center\", \"petrol station\", \"logistics\", \"courier\",\n",
    "        \"delivery\", \"shipping\", \"freight\", \"warehouse\", \"storage\", \"moving\",\n",
    "        \"relocation\", \"trucking\", \"cargo\", \"forwarding\", \"express\", \"postal delivery\"\n",
    "    ],\n",
    "    \n",
    "    \"Tourism\": [\n",
    "        \"hotel\", \"resort\", \"hostel\", \"accommodation\", \"tourist\", \"tourism\",\n",
    "        \"attraction\", \"museum\", \"gallery\", \"heritage\", \"cultural\", \"zoo\",\n",
    "        \"aquarium\", \"theme park\", \"entertainment\", \"casino\", \"cruise\",\n",
    "        \"tour\", \"travel\", \"vacation\", \"holiday\", \"sightseeing\", \"landmark\",\n",
    "        \"monument\", \"gardens\", \"park\", \"beach\", \"island\", \"sentosa\",\n",
    "        \"marina bay\", \"orchard\", \"chinatown\", \"little india\", \"adventure\",\n",
    "        \"recreation\", \"amusement\", \"leisure activities\", \"excursion\", \"safari\"\n",
    "    ],\n",
    "    \n",
    "    \"Community_spaces\": [\n",
    "        \"community\", \"center\", \"centre\", \"club\", \"association\", \"society\",\n",
    "        \"library\", \"sports\", \"gym\", \"fitness\", \"swimming\", \"pool\", \"court\",\n",
    "        \"field\", \"playground\", \"park\", \"garden\", \"recreational\", \"leisure\",\n",
    "        \"activity\", \"social\", \"gathering\", \"meeting\", \"event\", \"function\",\n",
    "        \"hall\", \"auditorium\", \"pavilion\", \"void deck\", \"common area\",\n",
    "        \"volunteer\", \"charity\", \"non-profit\", \"foundation\", \"welfare\", \"ngo\"\n",
    "    ],\n",
    "    \n",
    "    \"Government_services\": [\n",
    "        \"government\", \"ministry\", \"statutory board\", \"public\", \"civil service\",\n",
    "        \"town council\", \"hdb office\", \"cpf\", \"iras\", \"mom\", \"moe\", \"moh\",\n",
    "        \"court\", \"tribunal\", \"registry\", \"authority\", \"agency\", \"commission\",\n",
    "        \"municipal\", \"grassroots\", \"pa\", \"people's association\", \"cc\",\n",
    "        \"community center\", \"rc\", \"residents committee\", \"official\",\n",
    "        \"parliament\", \"embassy\", \"consulate\", \"immigration\", \"customs\", \"ica\"\n",
    "    ],\n",
    "    \n",
    "    \"Retail_services\": [\n",
    "        \"retail\", \"shop\", \"store\", \"mart\", \"department store\", \"shopping\",\n",
    "        \"mall\", \"plaza\", \"fashion\", \"clothing\", \"electronics\", \"jewelry\",\n",
    "        \"jewellery\", \"hardware\", \"bookstore\", \"optical\", \"sporting goods\",\n",
    "        \"furniture\", \"toys\", \"pet\", \"beauty\", \"cosmetic\", \"salon\", \"spa\",\n",
    "        \"restaurant\", \"cafe\", \"coffee\", \"bar\", \"pub\", \"food court\", \"dining\",\n",
    "        \"catering\", \"bakery\", \"food\", \"beverage\", \"hawker\", \"entertainment\",\n",
    "        \"cinema\", \"ktv\", \"karaoke\", \"massage\", \"trading\", \"wholesale\",\n",
    "        \"import\", \"export\", \"distribution\", \"sales\", \"business\", \"commercial\",\n",
    "        \"manufacturing\", \"production\", \"processing\", \"packaging\", \"assembly\",\n",
    "        \"fabrication\", \"construction\", \"building\", \"renovation\", \"interior\",\n",
    "        \"design\", \"architecture\", \"engineering\", \"consulting\", \"advisory\",\n",
    "        \"professional services\", \"legal\", \"accounting\", \"finance\", \"insurance\",\n",
    "        \"real estate\", \"property\", \"investment\", \"marketing\", \"advertising\",\n",
    "        \"media\", \"publishing\", \"printing\", \"technology\", \"software\", \"it\",\n",
    "        \"computer\", \"digital\", \"online\", \"internet\", \"web\", \"app\", \"system\",\n",
    "        \"development\", \"programming\", \"data\", \"analytics\", \"research\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ========================================================\n",
    "# PART 4: UPDATED Classification Function (REMOVED METHOD 3)\n",
    "# ========================================================\n",
    "\n",
    "def classify_business_description_no_method3(description: str, use_mediapipe: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Classify business description using ONLY:\n",
    "    1. MediaPipe for general sentiment/category hints\n",
    "    2. Keyword matching for specific Singapore business types\n",
    "    3. NO aggressive fallback logic (removed Method 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    description_lower = description.lower()\n",
    "    \n",
    "    # Method 1: Keyword-based classification (primary)\n",
    "    category_scores = {}\n",
    "    \n",
    "    for category, keywords in category_keywords.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in description_lower:\n",
    "                # Weight longer, more specific keywords higher\n",
    "                weight = len(keyword.split()) * 2 if len(keyword.split()) > 1 else 1\n",
    "                score += weight\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if score > 0:\n",
    "            category_scores[category] = {\n",
    "                'score': score,\n",
    "                'keywords': matched_keywords,\n",
    "                'confidence': min(score / 10.0, 1.0)  # Normalize confidence\n",
    "            }\n",
    "    \n",
    "    # Method 2: Use MediaPipe for additional insights\n",
    "    mediapipe_result = None\n",
    "    if use_mediapipe:\n",
    "        try:\n",
    "            classification_result = classifier.classify(description)\n",
    "            if classification_result.classifications:\n",
    "                # Extract top classification\n",
    "                top_classification = classification_result.classifications[0]\n",
    "                if top_classification.categories:\n",
    "                    top_category = top_classification.categories[0]\n",
    "                    mediapipe_result = {\n",
    "                        'category': top_category.category_name,\n",
    "                        'score': top_category.score\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            print(f\"MediaPipe classification error: {e}\")\n",
    "    \n",
    "    # REMOVED METHOD 3 - No aggressive fallback logic\n",
    "    \n",
    "    # Final decision logic\n",
    "    if category_scores:\n",
    "        # Get category with highest score\n",
    "        best_category = max(category_scores.items(), key=lambda x: x[1]['score'])\n",
    "        \n",
    "        primary_category = best_category[0]\n",
    "        confidence = best_category[1]['confidence']\n",
    "        keywords_matched = best_category[1]['keywords']\n",
    "        \n",
    "        # Get secondary categories if they exist\n",
    "        secondary_categories = [cat for cat, data in category_scores.items() \n",
    "                             if cat != primary_category and data['score'] >= 2]\n",
    "        \n",
    "        all_categories = [primary_category] + secondary_categories[:2]  # Max 3 categories\n",
    "        \n",
    "        return all_categories, confidence, keywords_matched\n",
    "    \n",
    "    else:\n",
    "        # Only assign to Others if truly no keywords matched\n",
    "        return ['Others'], 0.1, ['no_keywords_matched']\n",
    "\n",
    "# ========================================================\n",
    "# PART 5: Apply Classification to Sample\n",
    "# ========================================================\n",
    "\n",
    "print(\"Starting classification without Method 3 fallback logic...\")\n",
    "print(f\"Processing {len(df):,} records...\")\n",
    "\n",
    "# Process sample\n",
    "results = []\n",
    "for desc in tqdm(df[col_name].astype(str).tolist(), desc=\"Classifying\"):\n",
    "    result = classify_business_description_no_method3(desc)\n",
    "    results.append(result)\n",
    "\n",
    "# Unpack results\n",
    "categories_list, confidences, keywords_matched = zip(*results)\n",
    "\n",
    "df['amenity_categories'] = [', '.join(cats) for cats in categories_list]\n",
    "df['classification_confidence'] = confidences\n",
    "df['keywords_matched'] = [', '.join(kw) for kw in keywords_matched]\n",
    "\n",
    "# Save results\n",
    "output_file = \"acra_sample_no_method3.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Sample results saved to: {output_file}\")\n",
    "\n",
    "# ========================================================\n",
    "# PART 6: Analysis and Comparison\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION RESULTS - WITHOUT METHOD 3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Category distribution\n",
    "category_counts = (\n",
    "    df['amenity_categories']\n",
    "    .str.split(', ')\n",
    "    .explode()\n",
    "    .value_counts()\n",
    ")\n",
    "\n",
    "print(f\"\\nCategory Distribution:\")\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{category:25}: {count:,} ({percentage:5.1f}%)\")\n",
    "\n",
    "# Key metrics\n",
    "retail_pct = (category_counts.get('Retail_services', 0) / len(df)) * 100\n",
    "others_pct = (category_counts.get('Others', 0) / len(df)) * 100\n",
    "\n",
    "print(f\"\\n🎯 Key Metrics:\")\n",
    "print(f\"Retail_services: {retail_pct:.1f}%\")\n",
    "print(f\"Others: {others_pct:.1f}%\")\n",
    "\n",
    "# Confidence analysis\n",
    "high_conf = len(df[df['classification_confidence'] >= 0.7])\n",
    "medium_conf = len(df[(df['classification_confidence'] >= 0.4) & \n",
    "                     (df['classification_confidence'] < 0.7)])\n",
    "low_conf = len(df[df['classification_confidence'] < 0.4])\n",
    "\n",
    "print(f\"\\nConfidence Distribution:\")\n",
    "print(f\"High confidence (≥0.7): {high_conf:,} ({high_conf/len(df)*100:.1f}%)\")\n",
    "print(f\"Medium confidence (0.4-0.7): {medium_conf:,} ({medium_conf/len(df)*100:.1f}%)\")\n",
    "print(f\"Low confidence (<0.4): {low_conf:,} ({low_conf/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Show examples of each category\n",
    "print(f\"\\n📋 SAMPLE CLASSIFICATIONS BY CATEGORY:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for category in category_counts.index[:10]:  # Top 10 categories\n",
    "    sample_records = df[df['amenity_categories'].str.contains(category, na=False)].head(3)\n",
    "    print(f\"\\n{category}:\")\n",
    "    for idx, row in sample_records.iterrows():\n",
    "        desc = row[col_name][:60] + \"...\" if len(row[col_name]) > 60 else row[col_name]\n",
    "        print(f\"  • {desc} (conf: {row['classification_confidence']:.2f})\")\n",
    "\n",
    "# Show Others category examples for analysis\n",
    "others_examples = df[df['amenity_categories'] == 'Others'].head(10)\n",
    "print(f\"\\n❓ EXAMPLES OF 'Others' CATEGORY:\")\n",
    "print(\"-\" * 100)\n",
    "for idx, row in others_examples.iterrows():\n",
    "    desc = row[col_name][:80] + \"...\" if len(row[col_name]) > 80 else row[col_name]\n",
    "    print(f\"  • {desc}\")\n",
    "\n",
    "print(f\"\\n✅ ANALYSIS COMPLETE!\")\n",
    "print(f\"📊 Total sample processed: {len(df):,} records\")\n",
    "print(f\"📉 Retail_services reduced from ~70% to {retail_pct:.1f}%\")\n",
    "print(f\"📈 Others increased to {others_pct:.1f}%\")\n",
    "print(f\"💾 Results saved to: {output_file}\")\n",
    "\n",
    "print(f\"\\n🔍 RECOMMENDATION:\")\n",
    "if retail_pct < 30:\n",
    "    print(\"✅ Retail_services percentage looks much more reasonable now!\")\n",
    "    print(\"✅ The removal of Method 3 has successfully reduced the bias.\")\n",
    "    print(\"💡 You can now apply this updated logic to your full dataset.\")\n",
    "else:\n",
    "    print(\"⚠️  Retail_services is still high. Consider refining the keywords further.\")\n",
    "\n",
    "if others_pct > 40:\n",
    "    print(\"📝 High 'Others' percentage suggests we might need some targeted keywords\")\n",
    "    print(\"📝 Review the 'Others' examples above to identify common patterns\")\n",
    "else:\n",
    "    print(\"✅ 'Others' percentage is reasonable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39bec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ACRA FULL DATASET CLASSIFICATION - BATCH PROCESSING\n",
      "============================================================\n",
      "Batch size: 10,000 records\n",
      "Output files: ['acra_classified_part1v2.csv', 'acra_classified_part2v2.csv', 'acra_classified_part3v2.csv']\n",
      "============================================================\n",
      "Setting up MediaPipe Text Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757173324.538273   15117 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2\n",
      "W0000 00:00:1757173324.680654  370317 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full ACRA dataset...\n",
      "Full Dataset Shape: (951620, 15)\n",
      "Final dataset size: 951,620 records\n",
      "Total batches: 96\n",
      "Batches per file: [32, 32, 32]\n",
      "Records per file: [320000, 320000, 320000]\n",
      "\n",
      "Starting batch processing...\n",
      "Processing 951,620 records in 96 batches...\n",
      "\n",
      "--- Batch 1/96 ---\n",
      "Records 0 to 9,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 1/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|██████████| 10000/10000 [04:28<00:00, 37.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 52.3%, Others 10.6%\n",
      "Progress: 10,000/951,620 (1.1%)\n",
      "\n",
      "--- Batch 2/96 ---\n",
      "Records 10,000 to 19,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 2/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|██████████| 10000/10000 [04:31<00:00, 36.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 54.5%, Others 12.6%\n",
      "Progress: 20,000/951,620 (2.1%)\n",
      "\n",
      "--- Batch 3/96 ---\n",
      "Records 20,000 to 29,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 3/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|██████████| 10000/10000 [04:24<00:00, 37.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 68.9%, Others 6.5%\n",
      "Progress: 30,000/951,620 (3.2%)\n",
      "\n",
      "--- Batch 4/96 ---\n",
      "Records 30,000 to 39,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 4/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|██████████| 10000/10000 [04:27<00:00, 37.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 61.4%, Others 9.1%\n",
      "Progress: 40,000/951,620 (4.2%)\n",
      "\n",
      "--- Batch 5/96 ---\n",
      "Records 40,000 to 49,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 5/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|██████████| 10000/10000 [04:27<00:00, 37.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 62.7%, Others 8.0%\n",
      "Progress: 50,000/951,620 (5.3%)\n",
      "\n",
      "--- Batch 6/96 ---\n",
      "Records 50,000 to 59,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 6/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|██████████| 10000/10000 [12:14<00:00, 13.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 51.4%, Others 11.8%\n",
      "Progress: 60,000/951,620 (6.3%)\n",
      "\n",
      "--- Batch 7/96 ---\n",
      "Records 60,000 to 69,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 7/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7: 100%|██████████| 10000/10000 [04:26<00:00, 37.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 57.2%, Others 10.1%\n",
      "Progress: 70,000/951,620 (7.4%)\n",
      "\n",
      "--- Batch 8/96 ---\n",
      "Records 70,000 to 79,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 8/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 8: 100%|██████████| 10000/10000 [04:24<00:00, 37.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 63.0%, Others 7.6%\n",
      "Progress: 80,000/951,620 (8.4%)\n",
      "\n",
      "--- Batch 9/96 ---\n",
      "Records 80,000 to 89,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 9/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 9: 100%|██████████| 10000/10000 [04:24<00:00, 37.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 58.9%, Others 10.0%\n",
      "Progress: 90,000/951,620 (9.5%)\n",
      "\n",
      "--- Batch 10/96 ---\n",
      "Records 90,000 to 99,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 10/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 10: 100%|██████████| 10000/10000 [04:20<00:00, 38.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 56.1%, Others 9.5%\n",
      "Progress: 100,000/951,620 (10.5%)\n",
      "\n",
      "--- Batch 11/96 ---\n",
      "Records 100,000 to 109,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 11/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 11: 100%|██████████| 10000/10000 [04:22<00:00, 38.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 48.9%, Others 13.6%\n",
      "Progress: 110,000/951,620 (11.6%)\n",
      "\n",
      "--- Batch 12/96 ---\n",
      "Records 110,000 to 119,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 12/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 12: 100%|██████████| 10000/10000 [04:19<00:00, 38.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 51.2%, Others 14.7%\n",
      "Progress: 120,000/951,620 (12.6%)\n",
      "\n",
      "--- Batch 13/96 ---\n",
      "Records 120,000 to 129,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 13/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 13: 100%|██████████| 10000/10000 [04:21<00:00, 38.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 53.1%, Others 13.4%\n",
      "Progress: 130,000/951,620 (13.7%)\n",
      "\n",
      "--- Batch 14/96 ---\n",
      "Records 130,000 to 139,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 14/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 14: 100%|██████████| 10000/10000 [18:09<00:00,  9.18it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 64.0%, Others 8.5%\n",
      "Progress: 140,000/951,620 (14.7%)\n",
      "\n",
      "--- Batch 15/96 ---\n",
      "Records 140,000 to 149,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 15/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 15: 100%|██████████| 10000/10000 [09:20<00:00, 17.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 64.0%, Others 7.0%\n",
      "Progress: 150,000/951,620 (15.8%)\n",
      "\n",
      "--- Batch 16/96 ---\n",
      "Records 150,000 to 159,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 16/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 16: 100%|██████████| 10000/10000 [12:54<00:00, 12.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 62.2%, Others 9.5%\n",
      "Progress: 160,000/951,620 (16.8%)\n",
      "\n",
      "--- Batch 17/96 ---\n",
      "Records 160,000 to 169,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 17/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 17: 100%|██████████| 10000/10000 [04:20<00:00, 38.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 59.7%, Others 10.0%\n",
      "Progress: 170,000/951,620 (17.9%)\n",
      "\n",
      "--- Batch 18/96 ---\n",
      "Records 170,000 to 179,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 18/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 18: 100%|██████████| 10000/10000 [04:23<00:00, 37.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 61.3%, Others 8.5%\n",
      "Progress: 180,000/951,620 (18.9%)\n",
      "\n",
      "--- Batch 19/96 ---\n",
      "Records 180,000 to 189,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 19/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 19: 100%|██████████| 10000/10000 [04:31<00:00, 36.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 48.8%, Others 12.3%\n",
      "Progress: 190,000/951,620 (20.0%)\n",
      "\n",
      "--- Batch 20/96 ---\n",
      "Records 190,000 to 199,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 20/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 20: 100%|██████████| 10000/10000 [15:45<00:00, 10.58it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 51.9%, Others 13.1%\n",
      "Progress: 200,000/951,620 (21.0%)\n",
      "\n",
      "--- Batch 21/96 ---\n",
      "Records 200,000 to 209,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 21/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 21: 100%|██████████| 10000/10000 [45:04<00:00,  3.70it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 60.7%, Others 10.9%\n",
      "Progress: 210,000/951,620 (22.1%)\n",
      "\n",
      "--- Batch 22/96 ---\n",
      "Records 210,000 to 219,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 22/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 22: 100%|██████████| 10000/10000 [21:46<00:00,  7.65it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 67.1%, Others 5.9%\n",
      "Progress: 220,000/951,620 (23.1%)\n",
      "\n",
      "--- Batch 23/96 ---\n",
      "Records 220,000 to 229,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 23/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 23: 100%|██████████| 10000/10000 [33:58<00:00,  4.91it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 66.5%, Others 7.5%\n",
      "Progress: 230,000/951,620 (24.2%)\n",
      "\n",
      "--- Batch 24/96 ---\n",
      "Records 230,000 to 239,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 24/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 24: 100%|██████████| 10000/10000 [25:37<00:00,  6.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 62.4%, Others 9.2%\n",
      "Progress: 240,000/951,620 (25.2%)\n",
      "\n",
      "--- Batch 25/96 ---\n",
      "Records 240,000 to 249,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 25/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 25: 100%|██████████| 10000/10000 [19:16<00:00,  8.65it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 56.7%, Others 10.6%\n",
      "Progress: 250,000/951,620 (26.3%)\n",
      "\n",
      "--- Batch 26/96 ---\n",
      "Records 250,000 to 259,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 26/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 26: 100%|██████████| 10000/10000 [26:40<00:00,  6.25it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 64.0%, Others 8.9%\n",
      "Progress: 260,000/951,620 (27.3%)\n",
      "\n",
      "--- Batch 27/96 ---\n",
      "Records 260,000 to 269,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 27/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 27: 100%|██████████| 10000/10000 [19:17<00:00,  8.64it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: acra_classified_part1v2.csv\n",
      "Batch stats: Retail 67.7%, Others 7.3%\n",
      "Progress: 270,000/951,620 (28.4%)\n",
      "\n",
      "--- Batch 28/96 ---\n",
      "Records 270,000 to 279,999\n",
      "Output: acra_classified_part1v2.csv\n",
      "File 1/3, Batch 28/32 in this file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 28:   0%|          | 24/10000 [00:00<05:11, 32.00it/s]"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# ACRA Amenity Classification - FULL DATASET PROCESSING\n",
    "# Process entire dataset in batches of 10,000 records\n",
    "# Split across 3 output files: acra_classified_part1v2.csv, part2v2.csv, part3v2.csv\n",
    "# Uses refined classification without Method 3 fallback logic\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import text\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# ========================================================\n",
    "# PART 0: Configuration\n",
    "# ========================================================\n",
    "\n",
    "BATCH_SIZE = 10000\n",
    "OUTPUT_FILES = [\n",
    "    \"acra_classified_part1v2.csv\",\n",
    "    \"acra_classified_part2v2.csv\", \n",
    "    \"acra_classified_part3v2.csv\"\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ACRA FULL DATASET CLASSIFICATION - BATCH PROCESSING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Batch size: {BATCH_SIZE:,} records\")\n",
    "print(f\"Output files: {OUTPUT_FILES}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ========================================================\n",
    "# PART 1: Setup MediaPipe Text Classifier\n",
    "# ========================================================\n",
    "\n",
    "print(\"Setting up MediaPipe Text Classifier...\")\n",
    "\n",
    "model_url = \"https://storage.googleapis.com/mediapipe-models/text_classifier/bert_classifier/float32/1/bert_classifier.tflite\"\n",
    "model_path = \"bert_classifier.tflite\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Downloading MediaPipe text classification model...\")\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "    print(\"Model downloaded successfully!\")\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = text.TextClassifierOptions(base_options=base_options)\n",
    "classifier = text.TextClassifier.create_from_options(options)\n",
    "\n",
    "# ========================================================\n",
    "# PART 2: Load Full Dataset\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading full ACRA dataset...\")\n",
    "df = pd.read_csv(\"acra_merged_active.csv\")\n",
    "print(f\"Full Dataset Shape: {df.shape}\")\n",
    "\n",
    "if \"primary_ssic_description\" in df.columns:\n",
    "    col_name = \"primary_ssic_description\"\n",
    "elif \"primary_ssic\" in df.columns:\n",
    "    col_name = \"primary_ssic\"\n",
    "else:\n",
    "    raise ValueError(\"No SSIC description column found in CSV\")\n",
    "\n",
    "# Clean dataset\n",
    "df = df.dropna(subset=[col_name])\n",
    "df[col_name] = df[col_name].astype(str).str.strip()\n",
    "\n",
    "total_records = len(df)\n",
    "total_batches = (total_records + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "print(f\"Final dataset size: {total_records:,} records\")\n",
    "print(f\"Total batches: {total_batches}\")\n",
    "\n",
    "# Calculate batches per file\n",
    "batches_per_file = total_batches // 3\n",
    "extra_batches = total_batches % 3\n",
    "\n",
    "file_batch_counts = [batches_per_file] * 3\n",
    "for i in range(extra_batches):\n",
    "    file_batch_counts[i] += 1\n",
    "\n",
    "print(f\"Batches per file: {file_batch_counts}\")\n",
    "print(f\"Records per file: {[count * BATCH_SIZE for count in file_batch_counts]}\")\n",
    "\n",
    "# ========================================================\n",
    "# PART 3: Classification Keywords (No Method 3)\n",
    "# ========================================================\n",
    "\n",
    "category_keywords = {\n",
    "    \"Emergency_services\": [\n",
    "        \"emergency\", \"ambulance\", \"fire\", \"police\", \"rescue\", \"paramedic\",\n",
    "        \"emergency medical\", \"fire station\", \"police station\", \"civil defence\",\n",
    "        \"scdf\", \"spf\", \"disaster\", \"crisis\", \"urgent care\", \"first aid\",\n",
    "        \"emergency response\", \"safety\", \"security services\", \"emergency care\",\n",
    "        \"security\", \"guard\", \"surveillance\", \"protection\", \"patrol\", \"investigation\"\n",
    "    ],\n",
    "    \n",
    "    \"Healthcare_facilities\": [\n",
    "        \"hospital\", \"clinic\", \"medical\", \"health\", \"dental\", \"doctor\", \"physician\",\n",
    "        \"specialist\", \"diagnostic\", \"laboratory\", \"physiotherapy\", \"tcm\",\n",
    "        \"traditional chinese medicine\", \"veterinary\", \"vet\", \"mental health\",\n",
    "        \"rehabilitation\", \"nursing\", \"healthcare\", \"medicine\", \"pharmaceutical\",\n",
    "        \"wellness\", \"therapy\", \"treatment\", \"surgery\", \"radiology\", \"dentist\",\n",
    "        \"medical center\", \"health screening\", \"pharmacy\", \"medical practice\",\n",
    "        \"acupuncture\", \"chiropractic\", \"optometry\", \"podiatry\", \"psychology\",\n",
    "        \"counseling\", \"counselling\", \"pathology\", \"dermatology\", \"cardiology\",\n",
    "        \"oncology\", \"pediatric\", \"geriatric\", \"therapeutic\", \"clinical\", \"dialysis\"\n",
    "    ],\n",
    "    \n",
    "    \"Essential_services\": [\n",
    "        \"bank\", \"atm\", \"post office\", \"utility\", \"electricity\", \"water\", \"gas\",\n",
    "        \"postal\", \"singpost\", \"supermarket\", \"grocery\", \"market\", \"provision\",\n",
    "        \"convenience store\", \"pharmacy\", \"petrol\", \"fuel\", \"gas station\",\n",
    "        \"essential\", \"basic services\", \"public utilities\", \"waste management\",\n",
    "        \"recycling\", \"laundry\", \"dry cleaning\", \"repair services\", \"maintenance\",\n",
    "        \"cleaning\", \"pest control\", \"plumbing\", \"electrical\", \"aircon\",\n",
    "        \"air conditioning\", \"hvac\", \"installation\", \"servicing\", \"telecom\",\n",
    "        \"telecommunications\", \"internet\", \"broadband\", \"cable\", \"satellite\",\n",
    "        \"mini mart\", \"7-eleven\", \"cheers\", \"fairprice\", \"cold storage\", \"sheng siong\"\n",
    "    ],\n",
    "    \n",
    "    \"Residential\": [\n",
    "        \"residential\", \"housing\", \"apartment\", \"condominium\", \"condo\", \"hdb\",\n",
    "        \"flat\", \"estate\", \"home\", \"house\", \"residence\", \"dwelling\", \"villa\",\n",
    "        \"bungalow\", \"townhouse\", \"maisonette\", \"penthouse\", \"serviced apartment\",\n",
    "        \"dormitory\", \"hostel\", \"boarding\", \"lodging\", \"quarters\", \"living\",\n",
    "        \"property management\", \"estate management\", \"facilities management\", \"tenant\"\n",
    "    ],\n",
    "    \n",
    "    \"Education_institutions\": [\n",
    "        \"school\", \"education\", \"kindergarten\", \"preschool\", \"primary\", \"secondary\",\n",
    "        \"university\", \"college\", \"polytechnic\", \"institute\", \"tuition\", \"enrichment\",\n",
    "        \"training\", \"learning\", \"academic\", \"student\", \"teacher\", \"instructor\",\n",
    "        \"course\", \"class\", \"lesson\", \"workshop\", \"seminar\", \"coaching\",\n",
    "        \"educational\", \"study\", \"tutorial\", \"academy\", \"nursery\", \"childcare\",\n",
    "        \"daycare\", \"student care\", \"after school\", \"language\", \"music\", \"art\",\n",
    "        \"dance\", \"martial arts\", \"swimming coaching\", \"examination\", \"skills training\"\n",
    "    ],\n",
    "    \n",
    "    \"Transport_services\": [\n",
    "        \"transport\", \"mrt\", \"lrt\", \"bus\", \"taxi\", \"grab\", \"station\", \"interchange\",\n",
    "        \"terminal\", \"airport\", \"changi\", \"port\", \"ferry\", \"boat\", \"marina\",\n",
    "        \"parking\", \"carpark\", \"car park\", \"garage\", \"vehicle\", \"automotive\",\n",
    "        \"workshop\", \"service center\", \"petrol station\", \"logistics\", \"courier\",\n",
    "        \"delivery\", \"shipping\", \"freight\", \"warehouse\", \"storage\", \"moving\",\n",
    "        \"relocation\", \"trucking\", \"cargo\", \"forwarding\", \"express\", \"postal delivery\"\n",
    "    ],\n",
    "    \n",
    "    \"Tourism\": [\n",
    "        \"hotel\", \"resort\", \"hostel\", \"accommodation\", \"tourist\", \"tourism\",\n",
    "        \"attraction\", \"museum\", \"gallery\", \"heritage\", \"cultural\", \"zoo\",\n",
    "        \"aquarium\", \"theme park\", \"entertainment\", \"casino\", \"cruise\",\n",
    "        \"tour\", \"travel\", \"vacation\", \"holiday\", \"sightseeing\", \"landmark\",\n",
    "        \"monument\", \"gardens\", \"park\", \"beach\", \"island\", \"sentosa\",\n",
    "        \"marina bay\", \"orchard\", \"chinatown\", \"little india\", \"adventure\",\n",
    "        \"recreation\", \"amusement\", \"leisure activities\", \"excursion\", \"safari\"\n",
    "    ],\n",
    "    \n",
    "    \"Community_spaces\": [\n",
    "        \"community\", \"center\", \"centre\", \"club\", \"association\", \"society\",\n",
    "        \"library\", \"sports\", \"gym\", \"fitness\", \"swimming\", \"pool\", \"court\",\n",
    "        \"field\", \"playground\", \"park\", \"garden\", \"recreational\", \"leisure\",\n",
    "        \"activity\", \"social\", \"gathering\", \"meeting\", \"event\", \"function\",\n",
    "        \"hall\", \"auditorium\", \"pavilion\", \"void deck\", \"common area\",\n",
    "        \"volunteer\", \"charity\", \"non-profit\", \"foundation\", \"welfare\", \"ngo\"\n",
    "    ],\n",
    "    \n",
    "    \"Government_services\": [\n",
    "        \"government\", \"ministry\", \"statutory board\", \"public\", \"civil service\",\n",
    "        \"town council\", \"hdb office\", \"cpf\", \"iras\", \"mom\", \"moe\", \"moh\",\n",
    "        \"court\", \"tribunal\", \"registry\", \"authority\", \"agency\", \"commission\",\n",
    "        \"municipal\", \"grassroots\", \"pa\", \"people's association\", \"cc\",\n",
    "        \"community center\", \"rc\", \"residents committee\", \"official\",\n",
    "        \"parliament\", \"embassy\", \"consulate\", \"immigration\", \"customs\", \"ica\"\n",
    "    ],\n",
    "    \n",
    "    \"Retail_services\": [\n",
    "        \"retail\", \"shop\", \"store\", \"mart\", \"department store\", \"shopping\",\n",
    "        \"mall\", \"plaza\", \"fashion\", \"clothing\", \"electronics\", \"jewelry\",\n",
    "        \"jewellery\", \"hardware\", \"bookstore\", \"optical\", \"sporting goods\",\n",
    "        \"furniture\", \"toys\", \"pet\", \"beauty\", \"cosmetic\", \"salon\", \"spa\",\n",
    "        \"restaurant\", \"cafe\", \"coffee\", \"bar\", \"pub\", \"food court\", \"dining\",\n",
    "        \"catering\", \"bakery\", \"food\", \"beverage\", \"hawker\", \"entertainment\",\n",
    "        \"cinema\", \"ktv\", \"karaoke\", \"massage\", \"trading\", \"wholesale\",\n",
    "        \"import\", \"export\", \"distribution\", \"sales\", \"business\", \"commercial\",\n",
    "        \"manufacturing\", \"production\", \"processing\", \"packaging\", \"assembly\",\n",
    "        \"fabrication\", \"construction\", \"building\", \"renovation\", \"interior\",\n",
    "        \"design\", \"architecture\", \"engineering\", \"consulting\", \"advisory\",\n",
    "        \"professional services\", \"legal\", \"accounting\", \"finance\", \"insurance\",\n",
    "        \"real estate\", \"property\", \"investment\", \"marketing\", \"advertising\",\n",
    "        \"media\", \"publishing\", \"printing\", \"technology\", \"software\", \"it\",\n",
    "        \"computer\", \"digital\", \"online\", \"internet\", \"web\", \"app\", \"system\",\n",
    "        \"development\", \"programming\", \"data\", \"analytics\", \"research\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ========================================================\n",
    "# PART 4: Classification Function (No Method 3)\n",
    "# ========================================================\n",
    "\n",
    "def classify_business_description(description: str, use_mediapipe: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Classify business description without Method 3 fallback logic\n",
    "    \"\"\"\n",
    "    description_lower = description.lower()\n",
    "    \n",
    "    # Method 1: Keyword-based classification\n",
    "    category_scores = {}\n",
    "    \n",
    "    for category, keywords in category_keywords.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in description_lower:\n",
    "                weight = len(keyword.split()) * 2 if len(keyword.split()) > 1 else 1\n",
    "                score += weight\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if score > 0:\n",
    "            category_scores[category] = {\n",
    "                'score': score,\n",
    "                'keywords': matched_keywords,\n",
    "                'confidence': min(score / 10.0, 1.0)\n",
    "            }\n",
    "    \n",
    "    # Method 2: MediaPipe (optional)\n",
    "    if use_mediapipe:\n",
    "        try:\n",
    "            classification_result = classifier.classify(description)\n",
    "            if classification_result.classifications:\n",
    "                top_classification = classification_result.classifications[0]\n",
    "                if top_classification.categories:\n",
    "                    top_category = top_classification.categories[0]\n",
    "                    # MediaPipe result available but not directly used in final decision\n",
    "        except Exception:\n",
    "            pass  # Silently handle MediaPipe errors\n",
    "    \n",
    "    # Final decision\n",
    "    if category_scores:\n",
    "        best_category = max(category_scores.items(), key=lambda x: x[1]['score'])\n",
    "        primary_category = best_category[0]\n",
    "        confidence = best_category[1]['confidence']\n",
    "        keywords_matched = best_category[1]['keywords']\n",
    "        \n",
    "        secondary_categories = [cat for cat, data in category_scores.items() \n",
    "                             if cat != primary_category and data['score'] >= 2]\n",
    "        \n",
    "        all_categories = [primary_category] + secondary_categories[:2]\n",
    "        return all_categories, confidence, keywords_matched\n",
    "    else:\n",
    "        return ['Others'], 0.1, ['no_keywords_matched']\n",
    "\n",
    "# ========================================================\n",
    "# PART 5: Batch Processing Loop\n",
    "# ========================================================\n",
    "\n",
    "print(f\"\\nStarting batch processing...\")\n",
    "print(f\"Processing {total_records:,} records in {total_batches} batches...\")\n",
    "\n",
    "current_file_index = 0\n",
    "batches_in_current_file = 0\n",
    "processed_records = 0\n",
    "\n",
    "for batch_num in range(total_batches):\n",
    "    # Check if we need to switch to next file\n",
    "    if batches_in_current_file >= file_batch_counts[current_file_index]:\n",
    "        current_file_index += 1\n",
    "        batches_in_current_file = 0\n",
    "        if current_file_index >= len(OUTPUT_FILES):\n",
    "            break\n",
    "    \n",
    "    # Calculate batch boundaries\n",
    "    start_idx = batch_num * BATCH_SIZE\n",
    "    end_idx = min((batch_num + 1) * BATCH_SIZE, total_records)\n",
    "    current_output_file = OUTPUT_FILES[current_file_index]\n",
    "    \n",
    "    print(f\"\\n--- Batch {batch_num + 1}/{total_batches} ---\")\n",
    "    print(f\"Records {start_idx:,} to {end_idx-1:,}\")\n",
    "    print(f\"Output: {current_output_file}\")\n",
    "    print(f\"File {current_file_index + 1}/3, Batch {batches_in_current_file + 1}/{file_batch_counts[current_file_index]} in this file\")\n",
    "    \n",
    "    # Extract batch\n",
    "    df_batch = df.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    # Process batch\n",
    "    results = []\n",
    "    for desc in tqdm(df_batch[col_name].astype(str).tolist(), \n",
    "                     desc=f\"Batch {batch_num + 1}\"):\n",
    "        result = classify_business_description(desc)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Unpack results\n",
    "    categories_list, confidences, keywords_matched = zip(*results)\n",
    "    \n",
    "    df_batch['amenity_categories'] = [', '.join(cats) for cats in categories_list]\n",
    "    df_batch['classification_confidence'] = confidences\n",
    "    df_batch['keywords_matched'] = [', '.join(kw) for kw in keywords_matched]\n",
    "    \n",
    "    # Save batch\n",
    "    if batches_in_current_file == 0:\n",
    "        # First batch in file - create with headers\n",
    "        df_batch.to_csv(current_output_file, index=False, mode='w')\n",
    "        print(f\"Created: {current_output_file}\")\n",
    "    else:\n",
    "        # Append without headers\n",
    "        df_batch.to_csv(current_output_file, index=False, mode='a', header=False)\n",
    "        print(f\"Appended to: {current_output_file}\")\n",
    "    \n",
    "    batches_in_current_file += 1\n",
    "    processed_records += len(df_batch)\n",
    "    \n",
    "    # Quick batch stats\n",
    "    batch_category_counts = (\n",
    "        df_batch['amenity_categories']\n",
    "        .str.split(', ')\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "    )\n",
    "    \n",
    "    retail_pct = (batch_category_counts.get('Retail_services', 0) / len(df_batch)) * 100\n",
    "    others_pct = (batch_category_counts.get('Others', 0) / len(df_batch)) * 100\n",
    "    \n",
    "    print(f\"Batch stats: Retail {retail_pct:.1f}%, Others {others_pct:.1f}%\")\n",
    "    print(f\"Progress: {processed_records:,}/{total_records:,} ({processed_records/total_records*100:.1f}%)\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    del df_batch, results, categories_list, confidences, keywords_matched\n",
    "    gc.collect()\n",
    "\n",
    "# ========================================================\n",
    "# PART 6: Final Summary\n",
    "# ========================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"BATCH PROCESSING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check all output files\n",
    "print(f\"\\nOutput File Summary:\")\n",
    "total_output_records = 0\n",
    "\n",
    "for i, output_file in enumerate(OUTPUT_FILES):\n",
    "    if os.path.exists(output_file):\n",
    "        try:\n",
    "            df_check = pd.read_csv(output_file)\n",
    "            records_count = len(df_check)\n",
    "            total_output_records += records_count\n",
    "            print(f\"{output_file}: {records_count:,} records\")\n",
    "            \n",
    "            # Quick stats for each file\n",
    "            category_counts = (\n",
    "                df_check['amenity_categories']\n",
    "                .str.split(', ')\n",
    "                .explode()\n",
    "                .value_counts()\n",
    "            )\n",
    "            retail_pct = (category_counts.get('Retail_services', 0) / len(df_check)) * 100\n",
    "            others_pct = (category_counts.get('Others', 0) / len(df_check)) * 100\n",
    "            print(f\"  → Retail: {retail_pct:.1f}%, Others: {others_pct:.1f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{output_file}: Error reading - {e}\")\n",
    "    else:\n",
    "        print(f\"{output_file}: Not created\")\n",
    "\n",
    "print(f\"\\nTotal output records: {total_output_records:,}\")\n",
    "print(f\"Original records: {total_records:,}\")\n",
    "print(f\"Success rate: {total_output_records/total_records*100:.1f}%\")\n",
    "\n",
    "if total_output_records == total_records:\n",
    "    print(f\"\\n✅ SUCCESS! All records processed successfully.\")\n",
    "    print(f\"📁 Data split across 3 files as requested.\")\n",
    "    print(f\"🎯 Classification completed without Method 3 bias.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Warning: Record count mismatch.\")\n",
    "\n",
    "print(f\"\\n🏁 PROCESSING COMPLETE!\")\n",
    "print(f\"Your classified data is ready in the v2 files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c74150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved as acra_classified_merged.csv with 951620 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Read CSVs directly ---\n",
    "df1 = pd.read_csv(\"acra_classified_part1.csv\")\n",
    "df2 = pd.read_csv(\"acra_classified_part2.csv\")\n",
    "df3 = pd.read_csv(\"acra_classified_part3.csv\")\n",
    "\n",
    "# --- Concatenate ---\n",
    "merged = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# --- Drop duplicates if needed ---\n",
    "merged = merged.drop_duplicates()\n",
    "\n",
    "# --- Save ---\n",
    "merged.to_csv(\"acra_classified_merged.csv\", index=False)\n",
    "\n",
    "print(f\"Merged file saved as acra_classified_merged.csv with {len(merged)} rows\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
